---
title: "Sources in unbounded media"
jupyter: python3
---

In this chapter, we will consider finite sources in unbounded media. In geo-electromagnetic applications, magnetic dipoles, electric dipoles, long grounded cables, and large loops are used as sources.

However, until now, we have studied induction in a source-free, uniform region, where we have coupled the source current contribution by boundary conditions, such as an inducing uniform, plane wave magnetic field in the Air halfspace.

We will address the following topics:

-   Polarization vectors
-   Potentials
-   Gauge conditions
-   Green's function of the uniform full-space
-   Electric and magnetic dipole sources in full-space.

## Polarization vectors

In the absence of matter, we observe that $$
\mathbf d - \varepsilon_0 \mathbf e = \mathbf 0
$$ and $$
\mu_0^{-1} \mathbf b - \mathbf h = \mathbf 0.
$$ When the differences are non-zero, then we observe the response of matter. We define the *electrical polarization* $\mathbf p$ $$
\mathbf p = \mathbf d - \varepsilon_0 \mathbf e
$$ and the magnetic polarization or magnetization $\mathbf m$ $$
\mathbf m = \mu_0^{-1} \mathbf b - \mathbf h
$$ The polarization vectors $\mathbf p$ and $\mathbf m$ are parallel and proportional to $\mathbf e$ and $\mathbf h$, resp.

We are able to quantify the polarization properties by the electrical susceptibility $\chi_e$ and magnetic susceptibility $\chi_m$. The latter is often referred to as the magnetic susceptibility $\kappa$.

We define $$
\mathbf p := \chi_e \varepsilon_0 \mathbf e = \mathbf d - \varepsilon_0 \mathbf e
$$ and likewise $$
\mathbf m := \chi_m \mathbf h = \mu_0^{-1} \mathbf b - \mathbf h.
$$ It follows for the relative dielectric permittivity $$
\varepsilon_r = 1 + \chi_e
$$ and for the relative magnetic permeability $$
\mu_r = 1 + \chi_m = 1 + \kappa.
$$

To implement technical sources, we separate the polarization into induced (superscript $i$) and external (superscript $s$) contributions to the observed fields: $$
\mathbf p = \mathbf p^i + \mathbf p^s = \mathbf d - \varepsilon_0 \mathbf e.
$$ Then, $$
\mathbf d = [\underbrace{\varepsilon_0 \mathbf e}_\text{free space} + \underbrace{\mathbf p^i}_\text{matter}] + \mathbf p^s
$$ and $$
\mathbf b = [\underbrace{\mu_0 \mathbf h}_\text{free space} + \underbrace{\mu_0 \mathbf m^i}_\text{matter}] + \mu_0 \mathbf m^s
$$

With the introduction of the polarization vectors, we are now able to augment Maxwell's equations, such that $$
\begin{align}
\nabla \times \mathbf h & = \mathbf j + \varepsilon \partial_t \mathbf e + \partial_t \mathbf p^s \\
\nabla \times \mathbf e & = \phantom{\mathbf j} -\mu \partial_t \mathbf h - \mu_0 \partial_t \mathbf m^s
\end{align}
$$

We define the *source current densities* in the magnetic and electric case as $$
\mathbf j_m^s := \mu_0 \partial_t \mathbf m^s 
$$ and $$
\mathbf j_e^s := \phantom{\mu_0} \partial_t \mathbf p^s .
$$

Now, we extend our definitions to the frequency domain: $$
\mathbf J_m^s := i \omega \mu_0 \mathbf M^s 
$$ and $$
\mathbf J_e^s := i \omega \mathbf P^s .
$$

::: {.callout-note title="Example"}
We consider a magnetic dipole at the point $\mathbf r_0 = [0, 0, -h]^\top, h > 0$.

The point of observation is at $\mathbf r = [x, y, z]^\top$.

The location of the dipole can now be pinned to $\mathbf r_0$ using a Dirac delta function.

We obtain $$
\mathbf M^s(\mathbf r) = \mathbf m \, \delta(\mathbf r - \mathbf r_0)
$$ with $\mathbf m$ the oriented *magnetic dipole moment*. The dipole moment has the physical dimension of $[\mathbf m] =$ A$\cdot m^2$. It can be interpreted as a current $I$ measured in A enclosing a surface measured in $m^2$.

As a vector quantity, the dipole moment has a direction. Its direction is given by the unit vector normal to the surface of the enclosed area.

A useful special case arises when the dipole is aligned with one of the Cartesian axes.

This way, we can define a vertical or horizontal dipole.
:::

## Electromagnetic potentials

Let's assume that electric and magnetic fields originate from *either* a magnetic or an electric source, i.e., $$
\begin{align}
\mathbf E & = \mathbf E_m + \mathbf E_e \\
\mathbf H & = \mathbf H_m + \mathbf H_e
\end{align}
$$ When $\mathbf J_e \equiv 0$, then we only observe the set of fields $[\mathbf E_m, \mathbf H_m]$.

When $\mathbf J_m \equiv 0$, then we only observe the set of fields $[\mathbf E_e, \mathbf H_e]$.

The two sets are disjoint. We insert into Maxwell's equations $$
\begin{align}
\nabla \times \mathbf E_m & = -i \omega \mu \mathbf H_m \textcolor{red}{- \mathbf J_m^s} \\
\nabla \times \mathbf H_m & = (\sigma + i \omega \varepsilon) \mathbf E_m
\end{align}
$$

$$
\begin{align}
\nabla \times \mathbf E_e & = -i \omega \mu \mathbf H_e  \\
\nabla \times \mathbf H_e & = (\sigma + i \omega \varepsilon) \mathbf E_e \textcolor{red}{+ \mathbf J_e^s}
\end{align}
$$

Now we apply the divergence to all of the above equations. Here we employ the identity $$
\nabla \cdot (\nabla \times \mathbf F) = 0,
$$ {#eq-divrot} such that, e.g., $$
\underbrace{\nabla \cdot (\nabla \times \mathbf E_m)}_{=0}  = -i \omega \mu \nabla \cdot \mathbf H_m - \nabla \cdot \mathbf J_m^s.
$$ We obtain $$
\begin{align}
\nabla \cdot \mathbf H_m & = -\frac{ \nabla \cdot \mathbf J_m^s }{i \omega \mu } \\
\nabla \cdot \mathbf E_e & = -\frac{ \nabla \cdot \mathbf J_e^s }{\sigma + i \omega \varepsilon } \\
\nabla \cdot \mathbf H_e & = 0 \\
\nabla \cdot \mathbf E_m & = 0.
\end{align}
$$ Since the divergence of $\mathbf H_e$ and $\mathbf E_m$ are zero, we can express both fields by the curl of an arbitrary vector field according to @eq-divrot. However, this vector field must fulfill Maxwell's equations. The following ansatz employing the vector potentials $\mathbf F$ and $\mathbf A$ meets this requirement: $$
\begin{align}
\mathbf E_m & = -\nabla \times \mathbf F \\
\mathbf H_e & = \phantom{-} \nabla \times \mathbf A.
\end{align}
$$ It follows $$
\begin{align}
\nabla \times \mathbf H_m & = -(\sigma + i \omega \varepsilon) \nabla \times \mathbf F \\
\nabla \times \mathbf E_e & = -i \omega \mu \nabla \times \mathbf A 
\end{align}
$$ from which we obtain $$
\begin{align}
\mathbf H_m & = -(\sigma + i \omega \varepsilon) \mathbf F - \nabla V \\
\mathbf E_e & = -i \omega \mu \mathbf A - \nabla U
\end{align}
$$ because of $$
\nabla \times \nabla u = \mathbf 0.
$$ The scalar potentials $V$ and $U$ are referred to as magnetic and electrical scalar potential, resp.

## The curl-curl equation for the potentials

Let's insert the potentials into Maxwell's equations.

$$
\begin{align}
\mathbf E_m & = - \nabla \times \mathbf F \\
\nabla \times \mathbf E_m & = - \nabla \times \nabla \times \mathbf F && = -i \omega \mu \textcolor{red}{\mathbf H_m} - \mathbf J^s_m \\
 &   && = i \omega \mu \textcolor{red}{(\sigma + i \omega \varepsilon) \mathbf F} + i \omega \mu \textcolor{red}{\nabla V} - \mathbf J^s_m
\end{align}
$$

$$
\begin{align}
\mathbf H_e & = \phantom{-} \nabla \times \mathbf A \\
\nabla \times \mathbf H_e & = \phantom{-} \nabla \times \nabla \times \mathbf A && = (\sigma + i \omega \varepsilon) \textcolor{red}{\mathbf E_e} + \mathbf J^s_e \\
 &   && = \textcolor{red}{-i \omega \mu} (\sigma + i \omega \varepsilon) \textcolor{red}{\mathbf A} - i \omega \mu \textcolor{red}{\nabla U} + \mathbf J^s_e
\end{align}
$$

We use the vector identity @eq-vector-identity and obtain

$$
\begin{align}
-\nabla^2 \mathbf F + \nabla \nabla \cdot \mathbf F + i \omega \mu (\sigma + i \omega \varepsilon) \mathbf F + i \omega \mu \nabla V & = + \mathbf J^s_m \\
-\nabla^2 \mathbf A + \nabla \nabla \cdot \mathbf A + i \omega \mu (\sigma + i \omega \varepsilon) \mathbf A + i \omega \mu \nabla U & = + \mathbf J^s_e
\end{align}
$$

## The vector Helmholtz equations for the potentials

Question: How to get rid of $V$ and $U$?

We choose the arbitrary scalar potential $V, U$ such that it cancels with the expression $\nabla \cdot \mathbf F$ and $\nabla \cdot \mathbf A$, resp. $$
\begin{align}
\nabla \nabla \cdot \mathbf F & = - i \omega \mu \nabla V \\
\nabla \cdot \mathbf F & = - i \omega \mu V
\end{align}
$$ and obtain $$
-\nabla^2 \mathbf F + i \omega \mu (\sigma + i \omega \varepsilon) \mathbf F = + \mathbf J^s_m.
$$ or short $$
\nabla^2 \mathbf F + k^2 \mathbf F = -\mathbf J^s_m, \qquad k^2 = -i \omega \mu (\sigma + i \omega \varepsilon).
$$

::: {.callout title="Self study"}
Repeat the steps above for the case of $\mathbf A$.
:::

::: {.callout-note title="Summary"}
We have eliminated the scalar potentials $V$ and $U$ by use of the *Lorenz gauge*.

The vector potentials are solutions to $$
\nabla^2 \mathbf F + k^2 \mathbf F  = -\mathbf J^s_m
$$ {#eq-inhomogeneous-helmholtz-F} and $$
\nabla^2 \mathbf A + k^2 \mathbf A = -\mathbf J^s_e.
$$ {#eq-inhomogeneous-helmholtz-A}

These equations are called *inhomogeneous Helmholtz equations*.

Note that the vector potentials are *aligned* with the direction of the source current densities!
:::

## Solutions of the inhomogeneous Helmholtz equation

We now want to find solutions to the inhomogeneous vector Helmholtz equations.

Let's consider the potential $\mathbf A$ @eq-inhomogeneous-helmholtz-A.

To obtain a solution, we take the following steps:

1.  transform the expressions into the Fourier wave number domain
2.  solve the algebraic equation
3.  transform back into space domain

First, we need a useful definition of the Fourier transform. We follow a similar notation like that given in @eq-fourier, but instead of time and angular frequency we choose as variables the Cartesian coordinates $x, y, z$ and the corresponding wave numbers $k_x, k_y, k_z$.

We define the *3-D Fourier transform pair* $$
\begin{align}
\tilde{\mathbf A}(k_x, k_y, k_z) 
    & = \iiint\limits_{-\infty}^\infty \mathbf A(x,y,z) e^{-i(k_x x + k_y y + k_z z)}\, \mathrm d x \mathrm d y \mathrm d z \\
\mathbf A(x,y,z)  & = \frac{ 1 }{(2 \pi)^3 } \iiint\limits_{-\infty}^\infty \tilde{\mathbf A}(k_x, k_y, k_z) e^{+i(k_x x + k_y y + k_z z)} \, \mathrm d k_x \mathrm d k_y \mathrm d k_z
\end{align}
$$

Also required are the differentiation, convolution, and linearity properties of the Fourier transform.

We recognize that in a Cartesian coordinate system $$
\nabla^2 := \partial^2_{xx} + \partial^2_{yy} + \partial^2_{zz}
$$ and therefore $$
\partial^2_{xx} e^{-i k_x x} = -k_x^2 e^{-i k_x x} \text{ etc.}
$$

After transformation of @eq-inhomogeneous-helmholtz-F into the wave number domain, we have $$
(-k_x^2 - k_y^2 - k_z^2 + k^2) \tilde{\mathbf A} = -\tilde{\mathbf J}^s_m.
$$ Recall that $k^2 = -i \omega \mu (\sigma + i \omega \varepsilon)$.

After rearranging we obtain $$
\tilde{\mathbf A} = \tilde{\tilde{G}} \tilde{\mathbf J}^s_m
$$ {#eq-AGJ} with the scalar function $$
\tilde{\tilde{G}} = (k_x^2 + k_y^2 + k_z^2 - k^2)^{-1}.
$$ $\tilde{\tilde{G}}$ is the 3-D Fourier transform of what we will later refer to as *Green's function*.

We can obtain $\mathbf A$ directly in the spatial domain by evaluating a 3-D convolution integral, since @eq-AGJ is a multiplication in the wave number domain by exploiting the convolution property of the Fourier transform. Unfortunately, we still have not found an expression for $G$.

To this end, let's consider a PDE similar to @eq-inhomogeneous-helmholtz-A. The differences are important: First, the solution to the PDE is a scalar function $G$, second, the right-hand side of the equation is a Dirac impulse in space.

We depart from $$
\nabla^2 G + k^2 G = -\delta(x) \delta(y) \delta(z)
$$ {#eq-pde-G}

We take steps 1 and 2 as outlined above and obtain $$
\tilde{\tilde{G}} = (k_x^2 + k_y^2 + k_z^2 - k^2)^{-1}.
$$ To find $G$, we first transform back into space domain w.r.t. $z$ and obtain $$
\tilde{G(k_x, k_y, z)} = \frac{ 1 }{ 2 \pi} \int\limits_{-\infty}^{\infty}
\tilde{\tilde{G}} e^{i k_z z} \, \mathrm d k_z = \frac{ e^{-u|z|} }{ 2 u}
 $$ with $u = \sqrt{k_x^2 + k_y^2 - k^2}$.

Next, we carry out a 2-D Fourier transform w.r.t. $x$ and $y$: $$
G(x,y,z) = \frac{ 1 }{ 4 \pi^2} \iint\limits_{-\infty}^{\infty} \frac{ e^{-u|z|} }{ 2 u}
e^{i (k_x x + k_y y)} \, \mathrm d k_x  \mathrm d k_y
$$

Since $u$ is an axisymmetric function of $k_x$ and $k_y$, we use of the following *Hankel transform*: $$
\frac{ 1 }{ 4 \pi^2} \iint\limits_{-\infty}^{\infty} F(k_x^2 + k_y^2) 
e^{i (k_x x + k_y y)} \, \mathrm d k_x  \mathrm d k_y 
=
2 \pi \int\limits_0^\infty F(\lambda) J_0(\lambda R) \lambda \, \mathrm d \lambda,
$$ where $$
\lambda^2 = k_x^2 + k_y^2
$$ the horizontal wave number, $$
R^2 = x^2 + y^2
$$ the radial distance from the $z$-axis, and $$
F :=   \frac{ e^{-u|z|} }{ 2 u}, \quad u^2 = \lambda^2 - k^2.
$$

Finally, we obtain the integral $$
G(R, z) = \frac{ 1 }{ 4 \pi } \int\limits_0^\infty \frac{ \lambda  }{ u} e^{-u|z|} J_0(\lambda R) \, \mathrm d \lambda
$$ This is the *Sommerfeld integral*, from which we get with $r^2 = R^2 + z^2$ the function $$
G(r) = \frac{ 1 }{ 4 \pi r} e^{- i k r}.
$$

This is the *Green's function for the uniform conductive fullspace in the frequenccy domain*.

## The Green's function

The Green's function or the *impulse response* of the conductive fullspace in the frequency domain is

$$
G(r, \omega) = \frac{1}{4 \pi r} e^{- i k r} = \frac{1}{4 \pi r} e^{- i r \sqrt{\omega^2 \mu \varepsilon - i \omega \mu \sigma}}.
$$ To obtain the time-domain response $g(r,t)$, we apply the inverse Fourier transform, i.e., $$
g(r, t) = \frac{1}{2 \pi} \frac{1}{4 \pi r} \int\limits_{-\infty}^\infty
e^{- i r \sqrt{\omega^2 \mu \varepsilon - i \omega \mu \sigma}}
e^{i \omega t}
\mathrm{d}\omega.
$$

### Free space

First, let's restrict to the free space case, where $\sigma=0$. We obtain $$ 
g(r,t) = \frac{1}{8 \pi^2 r} \int \limits_{-\infty}^\infty
e^{i \omega (t \pm r \sqrt{\mu \varepsilon}) } \mathrm{d}\omega.
$$ To obtain $g$, we need the *shifting property* of the Fourier transform: $$ 
\delta(t \pm t') =  \frac{1}{2 \pi} \int \limits_{-\infty}^\infty
e^{i \omega (t \pm t')}
\mathrm{d}\omega
$$ It follows that $$
g(r, t) = \frac{1 }{4 \pi r}  \delta(t - r / c)
$$ The sign is chosen such that causality is guaranteed, i.e., $$
g(r, t) = 0 \text{ for } t < 0.
$$ The result obtained above is called the *retarded potential*.

### Quasi-static approximation

For moderate to high conductivities and/or low frequencies, we have introduced the *quasi-static approximation*, which justifies that displacement currents may safely be neglected in geo-electromagnetic applications.

We start from the Green's function under quasi-static approximation: $$ 
G(r, \omega) = \frac{1}{4 \pi r} e^{-i r \sqrt{-i \omega \mu \sigma}} =
\frac{1}{4 \pi r} e^{-r \sqrt{i \omega \mu \sigma}}
$$ To obtain the time-domain Green's function, we apply the Laplace transform, which is as an integral transform similar to the Fourier transform, except that the former is restricted to transformations of functions of $t$ with $t \ge 0$. This is in accordance to the causality requirement stated above.

With the Laplace variable $s := i \omega$ we rewrite $$ 
G(r, s) = \frac{1}{4 \pi r} e^{-r \sqrt{s \mu \sigma}}
$$ From @Abramowitz1972 we obtain $$ 
g(r, t) = \frac{(\mu \sigma)^{1/2}}{(2 \pi t)^{3/2}}
e^{- \frac{\mu\sigma r^2}{4 t}} \, u(t)
$$

$u(t)$ is the Heaviside step function

$$
    u(t) = \begin{cases} 0 & t < 0 \\ 1 & t > 0. \end{cases}
$$

### Numerical experiments with the time-domain Green's function

We implement the Green's function in `Python` and plot it as a function of time or source-receiver-offset, resp.

At first, let's calculate the Green's function at a fixed distance of $r=100$ m for a time range of $t \in [10^{-6}, 10^{-2}]$ seconds.

The late time asymptotic $g(r,t) \sim t^{-3/2}$ as $t \to \infty$ is indicated as a straight line in the log-log plot.

```{python}
import numpy as np
import matplotlib.pyplot as plt

def green(sigma, r, t):
    mu = np.pi * 4e-7
    g = np.sqrt(mu * sigma) / (2 * np.pi * t)**1.5 * \
        np.exp(-0.25 * mu * sigma * r**2 / t)
    return g

sigma = 0.01
r = np.logspace(start=0, stop=4, num=41, endpoint=True)
t = np.logspace(start=-6, stop=-2, num=41, endpoint=True)

rfix = 100
tfix = 1e-6
g_t = [green(sigma, rfix, tt) for tt in t]
g_r = [green(sigma, rr, tfix) for rr in r]

fig, ax = plt.subplots(1, 1, figsize=(4,4), layout='constrained')
ax.loglog(t, g_t, label=r'$g(r,t)$')
ax.loglog(t, 1e-6 * t**(-1.5), label=r'$t^{-3/2}$')
ax.set_ylim((1e-4, 1e2))
ax.set_xlabel('t in s')
ax.set_ylabel(r'$g(r,t)$')
ax.set_title("r = " + str(rfix) + " m")
ax.grid(True)
ax.legend()
```

The following animation shows the interplay between the spatial decay of the Green's function with time on the left, and the evolution of the Green's function evaluated at a fixed point in space on the left.

Note the red dots and the red horizontal lines which links both subfigures to each other.

![](green_animation.gif)

## The fields of a dipole source in full-space

If we compare @eq-pde-G and @eq-inhomogeneous-helmholtz-F, we recognize the similarity of both PDEs. More specifically, if we would be able to orientate $\mathbf J$ in such a way that it would be aligned to one of the Cartesian axis, then $$
\mathbf J_m^s(\mathbf r) = i \omega \mu \mathbf m \delta^3(\mathbf r)
$$ would simplify for a vertically aligned dipole to $$
\mathbf J_m^s(\mathbf r) = i \omega \mu \begin{bmatrix}
0 \\ 0 \\ m
\end{bmatrix} \delta^3(\mathbf r) = 
\begin{bmatrix}
0 \\ 0 \\ J_m^s
\end{bmatrix}
$$ The vector-valued PDE @eq-inhomogeneous-helmholtz-F would turn into $$
\nabla^2 \mathbf F + k^2 \mathbf F = -i \omega \mu m \delta^3(\mathbf r) \mathbf e_z,
$$ hence, the scalar potential for a magnetic dipole aligned with the $z$-axis is $$
F_z = \mathbf F \cdot \mathbf e_z = \frac{ i \omega \mu m }{ 4 \pi r } e^{-i k r}.
$$

::: callout-tip
The potential of a dipole embedded in a uniform fullspace can be calculated with the help of the Green's function.

Dipole induction problems become particularly easy to solve when the dipole axis is aligned with a Cartesian axis.
:::

With the ansatz defined above $$
\mathbf E_m = - \nabla \times \mathbf F
$$ and $$
\mathbf H_m = \frac{ 1 }{ i \omega \mu } (\nabla \nabla \cdot \mathbf F + k^2 \mathbf F)
$$ we can calculate the components of the electric and magnetic fields in a straightforward manner.

Note that there are just spatial derivatives involved.

However, the symmetry of the problem suggests using cylindrical coordinates.

$$
\begin{align}
    \nabla \times \mathbf F = & \left(
        \frac{1}{r}
    \frac{\partial F_z}{\partial \varphi}-
    \frac{\partial F_\varphi}{\partial z}
    \right){\mathbf e_r} + \\
    & \left(\frac{\partial F_r}{\partial z}-
    \frac{\partial F_z}{\partial r}
    \right) {\mathbf e_\varphi} + \\
    & \frac{1}{r} \left(
        \frac{\partial \left(r F_\varphi\right)}{\partial r}-
    \frac{\partial F_r}{\partial \varphi}
    \right){\mathbf e_z}.
\end{align}
$$ {#eq-rot-cylindrical}

In the case of a dipole oriented in $z$-direction, the curl simplifies to 
$$
\nabla \times \mathbf F = - \frac{\partial F_z}{\partial r} \mathbf e_\varphi,
$$ {#eq-rot-F}
where $\mathbf e_\varphi$ is the unit coordinate vector in $\varphi$-direction.

::: {.callout-note}
Since the dipole axis is aligned with the $z$-axis, we expect axisymmetric field components.

The magnetic field forms closed field lines which are uniform in the azimuthal $\varphi$-direction.

For a magnetic dipole aligned with the $z$-direction we observe the field components
$$
E_\varphi,\quad H_r,\quad H_z.
$$

The components are mutual orthogonal!
:::

### Electric field

With the definition 
$$
 \mathbf E = -\nabla \times \mathbf F
$$ 
we find using @eq-rot-F that
$$
E_\varphi = \frac{\partial F_z}{\partial r}.
$$
Hence,
$$
E_\varphi = \partial_r F_z = -\frac{i \omega \mu m }{4 \pi r^2} (1 + i k r) \exp(-i k r).
$$

::: {.callout title="Self study"}
Do the derivation by yourself.
:::

The change of the basis from cylindrical to Cartesian coordinates requires for the horizontal components $$
\mathbf E = E_\varphi \mathbf e_\varphi = E_\varphi 
\begin{pmatrix}
-\sin\varphi \\
\cos\varphi
\end{pmatrix},
$$

since

$$
\begin{bmatrix}
\mathbf e_r \\ \mathbf e_\varphi \\ \mathbf e_z
\end{bmatrix}
=
\begin{bmatrix}
\cos\varphi & \sin\varphi & 0 \\
-\sin\varphi & \cos\varphi & 0 \\
0 & 0 & 1
\end{bmatrix}
\begin{bmatrix}
\mathbf e_x \\ \mathbf e_y \\ \mathbf e_z
\end{bmatrix}.
$$

With the angle $\varphi$ counting positive from the $x$-axis in the direction of $y$, we can use the relations

$$
\cos\varphi = \frac{x}{r}, \quad \sin\varphi = \frac{y}{r}.
$$

Hence, $$
\begin{align}
E_x & = +i \omega \mu m \frac{\sin\varphi}{4 \pi r^2}(1 + i k r) \exp(-i k r) \\
E_y & = -i \omega \mu m \frac{\cos\varphi}{4 \pi r^2}(1 + i k r) \exp(-i k r)
\end{align}
$$

A useful expression for an arbitrary orientation of the dipole is given by

$$
\mathbf E(\mathbf r) = -\frac{i \omega \mu}{4 \pi r^3} (1 + i k r) \exp(-i k r) \mathbf m \times \mathbf r,
$$

where the components of $\mathbf E$ depend on both the direction of the dipole moment and the direction to the source.

Check:

With $$
\mathbf m = 
\begin{bmatrix}
0 \\ 0 \\ m
\end{bmatrix}
$$ and $$
\mathbf r = 
\begin{bmatrix}
x \\ y \\ z
\end{bmatrix}
$$ we obtain $$
- \mathbf m \times \mathbf r = 
\begin{bmatrix}
my \\ -mx \\ 0
\end{bmatrix} = 
\begin{bmatrix}
m r \sin\varphi \\ -m r \cos\varphi \\ 0 
\end{bmatrix}
.
$$

::: callout-note
Looking in the direction of the positive $z$-axis of a right-handed coordinate system, the induced electric field is oriented counter-clockwise, when $\mathbf m$ is oriented in positive $z$-direction.
:::

### Magnetic field

For the magnetic field, we need 
$$
\mathbf H = -\sigma \mathbf F + \frac{1}{i\omega\mu} \nabla\nabla\cdot\mathbf F = \frac{1}{i\omega\mu} \left(
    k^2 \mathbf F + \nabla\nabla\cdot\mathbf F
\right).
$$ 

The $\nabla\cdot$-operator requires the calculation of $\partial_z F_z$, whereas the gradient requires to provide all partial derivatives of $\partial_z F_z$ with respect to $r$ and $z$.

We recall that
$$
r = \sqrt{x^2 + y^2 + z^2}
$$
and use the chain rule to obtain
$$
\partial_z F_z = \partial_r F_z \cdot \partial_z r,
$$
where
$$
\partial_z r = \frac{ z }{ r}.
$$

Further, the divergence and gradient operators generally read in cylindrical coordinates for a vector field $\mathbf F$ and  a scalar field $f$
$$
\nabla \cdot \mathbf F = \frac{1}{r} \partial_r(r F_r) + 
\frac{1}{r} \partial_\varphi F_\varphi +
\partial_z F_z
$$
and
$$
\nabla f = \partial_r f \mathbf e_r +
\frac{1}{r} \partial_\varphi f \mathbf e_\varphi +
\partial_z f \mathbf e_z.
$$

In our case we need to calculate
$$
\nabla \cdot \mathbf F = \partial_z F_z.
$$

To compute the derivatives, we use `sympy`:

```{python}
from sympy import diff, symbols, sqrt, pi, exp, I, simplify, Derivative, Matrix
x, y, z, r, omega, mu, sigma, m = symbols('x y z r omega mu_0 sigma m', real=True)
k = symbols('k')

Fz = I * omega * mu * m / (4 * pi * r) * exp(-I * k * r)
print('Fz = ')
Fz
```
Next, we implement an expression for $\nabla \cdot \mathbf F$:

```{python}
divF = diff(Fz.subs(r, sqrt(x**2 + y**2 + z**2)), z).subs(sqrt(x**2 + y**2 + z**2), r).simplify()
print('divF = ')
divF
```
The chain rule can be implemented by a `lambda` function `chain` which first substitutes $r$ by the square root, forms the derivative, and finally substitutes all square root expressions by $r$ or powers thereof.

```{python}
chain = lambda F, v: diff(F.subs(r, sqrt(x**2 + y**2 + z**2)), v).subs(sqrt(x**2 + y**2 + z**2), r).simplify()
```

A call to `chain`, i.e., the implementation of $\partial_z \partial_z F_z$ would simply look as follows:
```python
chain(Fz, z)
```
However, to get the magentic field components, we need to divide by the term $i \omega \mu_0$.

```{python}
Hx = chain(divF, x).factor() / (I * omega * mu)
print('Hx =')
Hx
```
```{python}
Hy = chain(divF, y).factor() / (I * omega * mu)
print('Hy =')
Hy
```

To get $H_z$ we have to add the term $k^2 F_z$ as
```{python}
Hz = (chain(divF, z) + k**2 * Fz) / (I * omega * mu)
print('Hz =')
Hz.factor().simplify()
```

We can generalize using the following notation:
$$
\mathbf H(\mathbf r) = \frac{1}{4 \pi r^3} \left[
    \frac{\mathbf m \cdot \mathbf r}{r^2} (3 + 3 i k r - k^2 r^2) \mathbf r - (1 + i k r - k^2 r^2) \mathbf m
    \right] e^{-i k r}.
$$

Let's check the validity on our example.

We introduce the symbolic vector quantities `M` and `R`, and implement a `lambda` function to express the magnetic field with respect to the orientation of the magnetic dipole moment: 
```{python}
M = Matrix([0, 0, m])
R = Matrix([x, y, z])
H = lambda M: (M.dot(R) * (3 + I * k * r - k**2 * r**2) * R / r**2 - (1 + I * k * r - k**2 * r**2) * M) * exp(-I * k * r) / (4 * pi * r**3)
print('H(M) =')
H(M)
```
This confirms the correctness of our derivation.

## Apparent resistivity

However, geophysics is primarily interested in reconstructing the spatial distribution of electrical conductivity from measured field quantities (inversion). 
This step is based on a model conception of the spatial conductivity distribution. 
In general, the conductivity is a function of location with $\sigma=\sigma(x,y,z)>0$.
In the simplest case, we assume that the halfspace or fullspace is a uniform conductor, i.e., $\sigma= const$. 
The model of the homogeneous halfspace or fullspace can therefore be completely described by a single number.
We now try to determine this number mathematically from the measured field quantities.

This is the simplest form of a geophysical inversion!

We use the _impedance_ to solve the problem. 
From this we then determine the apparent resistivity.

The following questions will be answered:

* Can the concept of impedance be transferred to dipole excitation?
* Is it possible to reconstruct the electrical resistivity from the impedance?
* What are the differences compared to homogeneous excitation (MT)?

We implement the general equations for the electric and magnetic fields as `Python` functions `E` and `H`, resp.:

```{python}
def E(r, m, f, sigma):
    mu = np.pi * 4e-7
    omega = 2 * np.pi * f
    iwm = 1j * omega * mu
    alpha = iwm / (4 * np.pi)
    k = np.sqrt(-iwm * sigma)
    x = r[0]
    y = r[1]
    z = r[2]
    R = np.linalg.norm(r)
    ikr = 1j * k * R
    E = -alpha / R**3 * (1.0 + ikr) * np.exp(-ikr) * np.cross(m, r)
    return E

def H(r, m, f, sigma):
    mu = np.pi * 4e-7
    omega = 2 * np.pi * f
    iwm = 1j * omega * mu
    k = np.sqrt(-iwm * sigma)
    x = r[0]
    y = r[1]
    z = r[2]
    R = np.linalg.norm(r)
    ikr = 1j * k * R
    k2r2 = k**2 * R**2
    H = np.exp(-ikr) / (4 * np.pi * R**3) * (
        
            np.dot(m, r) / R**2 * (3 + 3 * ikr - k2r2) * r
            -
            (1 + ikr - k2r2) * m
        )
    return H

```

We check with the following parameters:

* $\mathbf r = [100, 0, 0]^\top$ m
* $\mathbf m = [0, 0, 1]^\top$ A$\cdot m^2$
* $f = 100$ Hz
* $\sigma = 0.01$ S/m.

```{python}
r = np.array([100.0, 0.0, 0.0])
m = np.array([0.0, 0.0, 1.0])
f = 100.0
sigma = 0.01
e = E(r, m, f, sigma)
Ey = e[1]
e
```

```{python}
h = H(r, m, f, sigma)
Hz = h[2]
h
```
We recognize that for a vertically aligned dipole, when observed at the $x$-axis, only the $y$-component of $\mathbf E$ and the $z$-component of $\mathbf H$ are non-zero.

Now we try to calculate the _impedance_ from the ratio of two mutually orthogonal components of $\mathbf E$ and $\mathbf H$, e.g.,
$$
Z = \frac{ E_y }{ H_z}.
$$

```{python}
Z = Ey / Hz
Z
```

For the calculation of the apparent resistivity, we use
$$
\rho_a = \frac{ 1 }{ \omega \mu_0} |Z|^2
$$

```{python}
def rhoa(Z, f):
    mu = np.pi * 4e-7
    omega = 2 * np.pi * f
    return np.abs(Z)**2 / (omega * mu)
```

```{python}
rhoa(Z, f)
```

This does not meet our expectations.
We are therefore investigating whether the impedance depends on the frequency and/or the distance to the dipole.

We vary the frequencies and observe $\rho_a$ as a function of frequency.

```{python}
nf = 41
freq = np.logspace(1, 5, nf, endpoint=True)
Rhoa_f = [rhoa(E(r,m,v,sigma)[1] / H(r,m,v,sigma)[2], v) for v in freq]
```

```{python}
import matplotlib.pyplot as plt

plt.loglog(freq, Rhoa_f)
plt.grid(True)
plt.xlabel('f in Hz')
plt.ylabel(r'$\rho_a~in~\Omega\cdot m$')
plt.title('Dipole offset ' + str(np.linalg.norm(r)) + ' m')
plt.show()
```

Obviously, the value of $\rho_a$ depends on the frequency and asymptotically approaches the expected full-space value of the resistivity as $f \to \infty$.

We gain more insight, when we vary the distance to the dipole while keeping the frequency fixed.

```{python}
nr = 41
x = np.logspace(0, 4, nr, endpoint=True)
Rhoa_x = np.array([rhoa(E(np.array([v, 0, 0]),m,f,sigma)[1] / H(np.array([v, 0, 0]),m,f,sigma)[2], f) for v in x])
```

```{python}
plt.loglog(x, Rhoa_x)
plt.grid(True)
plt.xlabel('r in m')
plt.ylabel(r'$\rho_a~in~\Omega\cdot m$')
plt.title('Frequency ' + str(np.linalg.norm(f)) + ' Hz')
plt.show()
```

Is there a consistent explanation for these observations?
We look at the induction parameter $|k|r$ and revisit the parameters from the previous examples.

```{python}
def kr(f, sigma, r):
    mu = np.pi * 4e-7
    omega = 2 * np.pi * f
    return r * np.abs(np.sqrt(-1j * omega * mu * sigma))

def pos(data, threshold):
    return np.where(np.array(data) > threshold, data, np.nan)
```

```{python}
KR = np.array([kr(v, sigma, np.linalg.norm(r)) for v in freq])
plt.loglog(freq, KR, color='C1', label=r'|k|r > 1')
iind = np.argwhere(KR < 1)
plt.loglog(freq[iind], KR[iind], color='C0', label=r'|k|r < 1')
plt.legend()
plt.grid(True)
plt.ylabel(r'$|k|r$')
plt.xlabel('f in Hz')
plt.title('Dipole offset ' + str(np.linalg.norm(r)) + ' m')
plt.show()
```

With the indicator $|k|r$ just introduced, it is easier to determine which branch of the asymptotic we are on.

```{python}
KR = np.array([kr(f, sigma, v) for v in x])
plt.loglog(x, Rhoa_x, color='C1', label=r'$|k|r > 1$')
iind = np.argwhere(KR < 1)
plt.loglog(x[iind], Rhoa_x[iind], color='C0', label=r'$|k|r < 1$')
plt.legend()
plt.grid(True)
plt.xlabel('r in m')
plt.ylabel(r'$\rho_a~in~\Omega\cdot m$')
plt.title('Frequency ' + str(np.linalg.norm(f)) + ' Hz')
plt.show()
```

In contrast to homogeneous excitation, the impedance and thus the apparent resistivity for dipole excitation depends not only on the frequency but also on the distance between the dipole source and the receiver.
At $|k|r \gg 1$ we speak of the far zone. 
The impedance relationships there are similar to those for the MT.
At $|k|r \ll 1$ we are in the near zone. 
The induction parameter is small. 
The low induction number (LIN) methods work in this regime. With the Geonics EM-34, for example, a coil distance of around 10 m is selected at a frequency of 6,400 Hz. 
The induction parameter for this configuration is less than 1 if the conductivity is sufficiently low.

We check these findings for a range of conductivities.

```{python}
ns = 41
sigma = np.logspace(-4, 0, ns, endpoint=True)
r = 100.0
f = 100.0
KR = np.array([kr(f, v, r) for v in sigma])

Hz = np.array([H(np.array([r, 0, 0]), np.array([0, 0, 1]), f, v)[2] for v in sigma])

plt.semilogx(KR, np.real(Hz), label='Re')
plt.semilogx(KR, np.imag(Hz), label='Im')
plt.legend()
plt.grid(True)
plt.xlabel(r'$|k|r$')
plt.ylabel(r'$H_z$')
```