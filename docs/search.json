[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Theory of Electromagnetic Methods",
    "section": "",
    "text": "Prerequisites\nHere are the lecture notes for the 2024 module covering the Theory of Electromagnetic Methods. These notes are tailored for Master’s students of Geophysics and Geoinformatics at the Institute of Geophysics and Geoinformatics, TU Bergakademie Freiberg.\nYou can access all the materials on the GitHub repository https://github.com/ruboerner/ThEM.\nEnjoy studying!",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Theory of Electromagnetic Methods",
    "section": "Background",
    "text": "Background\nThis course targets Master’s students in their second semester, with a recommended understanding of fundamental geoelectromagnetic applications. Additionally, prior completion of the Theoretical Physics - Electrodynamics course is strongly advised as a prerequisite for this lecture.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "index.html#code",
    "href": "index.html#code",
    "title": "Theory of Electromagnetic Methods",
    "section": "Code",
    "text": "Code\nThe website’s course material includes sections with embedded Python code.\nYou can easily copy the code and execute it in a compatible Python runtime environment.\nFor an optimal experience, we recommend installing Python via miniconda.\nMoreover, you have the freedom to explore your own concepts and delve deeper into the course content by creating your personalized Jupyter notebooks. You can utilize any of the following platforms:\n\nVisual Studio Code\nJupyterlab\nQuarto\nmystMD.\n\nWorking with Jupyter Notebooks in Visual Studio Code is exceptionally straightforward.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "index.html#self-study",
    "href": "index.html#self-study",
    "title": "Theory of Electromagnetic Methods",
    "section": "Self study",
    "text": "Self study\nThere are individual small tasks for self-study that are scattered throughout the lecture.\n\n\n\n\n\n\nSelf study\n\n\n\nYou can easily identify these callouts.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "index.html#recommended-reading",
    "href": "index.html#recommended-reading",
    "title": "Theory of Electromagnetic Methods",
    "section": "Recommended Reading",
    "text": "Recommended Reading\nThe most important source of supplementary information is the book by Ward & Hohmann (1988).",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Theory of Electromagnetic Methods",
    "section": "License",
    "text": "License\nThis material is licensed under a Creative Commons License.\n\n\n\n\nWard, S.H. & Hohmann, G.W., 1988. Electromagnetic theory for geophysical applications. Electromagnetic methods in applied geophysics, Vol. 1, pp. 131–311.",
    "crumbs": [
      "Prerequisites"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "1  Preface",
    "section": "",
    "text": "These lecture notes serve as a supplement to the course.\nWe deal with the following problems:\n\nElectromagnetic fields and their mathematical description using Maxwell’s equations\nPartial differential equations and their solutions\nFields of dipole sources in a uniform fullspace\nDipole induction over a stratified halfspace\nTime-domain EM\nNumerical evaluation of Hankel integrals\nOutlook on numerical methods in 2D and 2D\n\nThe course deals in particular with all the details that serve to solve the problem of calculating airborne EM fields.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Electromagnetic fields",
    "section": "",
    "text": "2.1 Material properties\nIn electromagnetics we have the following material properties:\nIn the context of geo-electromagnetics, these parameters are associated with particular rock properties which are studied in petrophysics.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Electromagnetic fields</span>"
    ]
  },
  {
    "objectID": "intro.html#material-properties",
    "href": "intro.html#material-properties",
    "title": "2  Electromagnetic fields",
    "section": "",
    "text": "electrical conductivity \\(\\sigma\\)\ndielectrical permittivity \\(\\varepsilon\\)\nmagnetic permeability \\(\\mu\\).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Electromagnetic fields</span>"
    ]
  },
  {
    "objectID": "intro.html#simplifications",
    "href": "intro.html#simplifications",
    "title": "2  Electromagnetic fields",
    "section": "2.2 Simplifications",
    "text": "2.2 Simplifications\nAs we know from theroretical physics, the relations between the fields and the associated parameters are very general and allow, e.g., strong frequency-dependency or non-linearities.\nIn geo-electromagnetics, however, we can allow for a few simplifications.\nAll rock parameters are supposed to be\n\nlinear with respect to the fields\nstationary, and\nisotropic.\n\nWe will see later that anisotropy is a quite general rock property which needs to be considered in the interpretation of geo-electromagnetic field data.\nMoreover, we will first study the general properties of the EM induction in a uniform full-space by neglecting any spatial inhomogeneities of the parameters.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Electromagnetic fields</span>"
    ]
  },
  {
    "objectID": "fourier.html",
    "href": "fourier.html",
    "title": "3  Fourier transform",
    "section": "",
    "text": "3.1 Example\nIn this example we use a Fourier series expansion to approximate the periodic square function \\(u(x)\\) of length \\(2L\\).\nAn analytic formula for a square wave with unit amplitude and period \\(2L\\) is given by \\(u(x) = \\mathrm{sign}(\\sin(\\frac{\\pi x}{L})\\).\nShow the code\nx = np.arange(0, 4, 0.001)\nu = [np.sign(np.sin(np.pi * v / 2)) for v in x]\nfig, ax = plt.subplots(figsize=(4, 3))\nax.plot(x, u)\nax.fill_between(x, u, np.zeros_like(u), alpha=0.3)\nax.set_xlabel('x')\nax.set_ylabel('u(x)')\nax.set_title('Square wave')\nax.set_aspect('equal')\nax.grid(True)\nThe Fourier series expansion for a periodic square wave \\(u(x)\\) is\n\\[\nu(x) = \\lim_{N \\to \\infty} \\frac{4}{\\pi} \\sum_{n=1,3,5, \\ldots}^{N} \\frac{1}{n} \\sin \\left(\\frac{n \\pi x}{L}\\right).\n\\]\nA change of the running index \\(n\\) yields a representation which is better suited for numerical implementation:\n\\[\nu(x) = \\lim_{N \\to \\infty} \\frac{4}{\\pi} \\sum_{k=1}^{N} \\frac{1}{2k-1} \\sin \\left(\\frac{(2k-1) \\pi x}{L}\\right).\n\\]\nIn theory, the sequence of summations is infinite, whereas in general we deal with a truncated series, i.e., \\(N \\ll \\infty\\).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fourier transform</span>"
    ]
  },
  {
    "objectID": "fourier.html#example",
    "href": "fourier.html#example",
    "title": "3  Fourier transform",
    "section": "",
    "text": "3.1.1 Implementation\nFirst we write a Python function which calculates the individual sine terms\n\\[\nu_k(x) =  \\frac{1}{2k-1} \\sin \\left(\\frac{(2k-1) \\pi x}{L}\\right)\n\\]\nThis function is called uk and takes the arguments x and the index k. The window length L takes the default setting of 0.5.\n\n\nShow the code\ndef uk(x, k, L=0.5):\n    return np.sin(np.pi * (2 * k - 1) * x / L) / (2 * k - 1)\n\n\nNext, we implement the summation over all \\(k\\) sine terms, i.e., \\[\nu(x) \\approx \\frac{4}{\\pi} \\sum_{k=1}^N u_k(x)\n\\]\n\n\nShow the code\ndef u(x, k, L):\n    value = 4 / np.pi * \\\n        sum(uk(x, i, L) for i in range(1, k+1)) if k &gt; 0 else np.zeros_like(x)\n    return value\n\n\n\n\nShow the code\nL = 2\norder = 4\nx = np.arange(0, 2*L, 0.001)\nu_n = [np.sign(np.sin(np.pi * v / L)) for v in x]\nfig, ax = plt.subplots(nrows=2, ncols=1, sharex=True, layout='constrained')\nax[0].plot(x, u(x, order, L))\nax[0].fill_between(x, u_n, np.zeros_like(u_n), alpha=0.3)\n#ax[0].set_xlabel('x')\nax[0].set_ylabel('u(x)')\nax[0].set_title(f'Fourier series expansion for order={order}')\nax[0].set_aspect('equal')\nax[0].grid(True)\n\norder = 42\nax[1].plot(x, u(x, order, L))\nax[1].fill_between(x, u_n, np.zeros_like(u_n), alpha=0.3)\nax[1].set_xlabel('x')\nax[1].set_ylabel('u(x)')\nax[1].set_title(f'Fourier series expansion for order={order}')\nax[1].set_aspect('equal')\nax[1].grid(True);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote the Gibbs phenomenon at the jumps of the square wave. This is a typical behaviour of a piecewise differentiable continuous periodic function. As the expansion order gets large, the overshoot does not die out, but approaches a finite limit.\nIt can be shown that, for sufficiently large \\(N\\), the full overshooting is around 17.9 % larger than the jump in the original function.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Fourier transform</span>"
    ]
  },
  {
    "objectID": "maxwell.html",
    "href": "maxwell.html",
    "title": "4  Maxwell’s Equations",
    "section": "",
    "text": "4.1 Constitutive equations\nThe goal is to couple these equations. This can be achieved with the use of the constitutive equations, which are\n\\[\n\\begin{align}\n\\mathbf d & = \\varepsilon \\mathbf e \\\\\n\\mathbf b & = \\mu \\mathbf h\n\\end{align}\n\\tag{4.5}\\]\nGenerally, the linear parameters \\(\\varepsilon, \\mu\\) are rank-2 tensors represented as 3-by-3 matrices.",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maxwell's Equations</span>"
    ]
  },
  {
    "objectID": "maxwell.html#ohms-law",
    "href": "maxwell.html#ohms-law",
    "title": "4  Maxwell’s Equations",
    "section": "4.2 Ohm’s law",
    "text": "4.2 Ohm’s law\nIn an electrically conductive medium, any electric field gives rise to an electric current. This current is expressed by its current density as\n\\[\n\\mathbf j = \\sigma \\mathbf e,\n\\tag{4.6}\\]\nwhere \\(\\sigma\\) is a rank-2 tensor.\nThis tensor can be represented in matrix form as\n\\[\n\\sigma =   \\begin{pmatrix}    \\sigma_{11} & \\sigma_{12} & \\sigma_{13} \\\\    \\sigma_{21} & \\sigma_{22} & \\sigma_{23} \\\\    \\sigma_{31} & \\sigma_{32} & \\sigma_{33}   \\end{pmatrix}.\n\\]\nTensors like introduced here cause anisotropy, i.e., the material properties have different values across different spatial directions.\nA typical observation would be the deviation of the induced current density from the direction of the driving electric field.\n\n4.2.1 Remarks about anisotropy\nThe rank-2 tensor of electrical conductivity \\(\\tilde\\sigma\\) may be represented in matrix form as\n\\[\n  \\hat\\sigma =\n  \\begin{pmatrix}\n    \\sigma_{11} & \\sigma_{12} & \\sigma_{13} \\\\\n    \\sigma_{21} & \\sigma_{22} & \\sigma_{23} \\\\\n    \\sigma_{31} & \\sigma_{32} & \\sigma_{33}\n  \\end{pmatrix}.\n\\]\nAny real symmetric (n-by-n) matrix \\(A\\) can be diagonalized (principal axis theorem), such that\n\\[\nD_A = S^\\top A S  \n\\]\nis a diagonal matrix, and \\(S\\) is an orthogonal matrix.\nInterpreting the matrix \\(A\\) as a linear map in \\(\\mathbb {R} ^3\\), then the matrix \\(S\\) can be thought of as a transformation to the new basis. Between the old and new coordinates there is the relation \\(\\mathbf {x}=S \\boldsymbol {\\xi }\\). The action of the matrix \\(A\\) in the new coordinate system is taken over by the diagonal matrix \\(D_{A}\\).\nAfter transformation of the tensor in diagonal form, we have \\[\n  \\tilde\\sigma =\n  \\begin{pmatrix}\n    \\sigma_{xx} & 0 & 0 \\\\\n    0 & \\sigma_{yy} & 0 \\\\\n    0 & 0 & \\sigma_{zz}\n  \\end{pmatrix}.\n\\]\nIf \\(\\sigma_{xx} = \\sigma_{yy} = \\sigma_{zz} = \\sigma\\), then \\[\n  \\tilde\\sigma = \\sigma\n  \\begin{pmatrix}\n    1 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1\n  \\end{pmatrix} = \\sigma.\n\\] In this case, the conductivity does not depend on the spatial direction and hence is labelled isotropic.",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Maxwell's Equations</span>"
    ]
  },
  {
    "objectID": "pde.html",
    "href": "pde.html",
    "title": "5  Partial Differential Equations",
    "section": "",
    "text": "5.1 The curl-curl equation\nWe first eliminate one field from the set of Maxwell’s equations by applying the curl operator (\\(\\nabla \\times\\)) to one of the equations, i.e., Faraday’s law 4.2.\nThis results in a second-order PDE because we differentiate twice with respect to spatial coordinates.\nFinally, we obtain the curl-curl equation for the electric field \\(\\mathbf e\\) as \\[\n\\nabla \\times \\nabla \\times \\mathbf e  +\\mu \\sigma \\partial_t \\mathbf e + \\mu \\varepsilon \\partial^2_{tt} \\mathbf e = \\mathbf 0.\n\\tag{5.1}\\]\nThis is a second-order PDE with first- and second-order time derivatives.\nNote that you obtain a similar PDE for the magnetic field \\(\\mathbf h\\) if you apply the steps outlined above to Ampere’s law.\nOften, a slightly different form of 5.1 is used.\nThe following identity is useful for any vector field \\(\\mathbf f\\): \\[\n\\nabla \\times \\nabla \\times \\mathbf f = \\nabla \\nabla \\cdot \\mathbf f - \\nabla^2 \\mathbf f\n\\tag{5.2}\\]\nThis equation is useful, e.g., when \\(\\nabla \\cdot \\mathbf f = 0\\). In this case the curl-curl operator can be replaced by \\(-\\nabla^2\\), the vector Laplace operator defined over a vector field.\nUnder which conditions can we switch from the curl-curl to the Laplace operator? Clearly, the term \\(\\nabla \\nabla \\cdot \\mathbf f\\) must vanish (or its contribution must be negligible).",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "pde.html#the-curl-curl-equation",
    "href": "pde.html#the-curl-curl-equation",
    "title": "5  Partial Differential Equations",
    "section": "",
    "text": "Tip\n\n\n\n\n\n\\[\n\\begin{align}\n\\nabla \\times \\mathbf e  & = -\\partial_t \\mathbf b \\\\\n\\nabla \\times \\nabla \\times \\mathbf e & = \\nabla \\times (-\\partial_t \\mathbf b) \\\\\n  & = -\\nabla \\times (\\partial_t \\mathbf b) \\\\\n  & = -\\partial_t\\nabla \\times  \\mathbf b \\\\\n  & = -\\partial_t\\nabla \\times ( \\mu \\mathbf h) \\\\\n  & = -\\partial_t \\mu \\nabla \\times \\mathbf h \\\\\n  & = -\\mu \\partial_t \\nabla \\times \\mathbf h \\\\\n  & = -\\mu \\partial_t (\\mathbf j + \\partial_t \\mathbf d) \\\\\n  & = -\\mu \\partial_t (\\sigma \\mathbf e + \\partial_t \\mathbf d) \\\\\n  & -\\mu \\partial_t (\\sigma \\mathbf e + \\partial_t \\varepsilon \\mathbf e) \\\\\n  & = -\\mu \\partial_t \\sigma \\mathbf e -\\mu \\partial^2_{tt} \\varepsilon \\mathbf e \\\\\n  & = -\\mu \\sigma \\partial_t \\mathbf e -\\mu \\varepsilon \\partial^2_{tt} \\mathbf e\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe vector Laplacian is similar to the scalar Laplacian. The scalar Laplacian applies to a scalar field and returns a scalar quantity, whereas the vector Laplacian applies to a vector field and returns a vector quantity.\nIn Cartesian coordinates, the returned vector field is equal to the vector field of the scalar Laplacian applied to each vector component.\n\n\n\n\n5.1.1 Decay of free charges\nWhen the electric field \\(\\mathbf e\\) is considered, we are faced with the following problem: Under which conditions \\(\\nabla \\cdot \\mathbf e\\) becomes negligible small?\nThe answer should be clear: When there are no free charges present in the considered domain, there is no associated electric field.\nRecall, that in a uniform dielectric medium there holds Gauß’ s law for electric charges\n\\[\n\\nabla \\cdot \\mathbf e = \\frac{\\rho_E}{\\varepsilon},\n\\]\nwhere \\(\\rho_E\\) is the volume charge density and \\(\\varepsilon = \\varepsilon_r \\varepsilon_0\\) is the permittivity.\nLet’s find out how to solve the problem.\nWe want to show that \\(\\nabla \\cdot \\mathbf e \\approx 0\\) for some time \\(t&gt;0\\). As long as \\(t \\le 0\\), there is a certain charge density \\(\\rho_E(t)\\) concentrated at, e.g., the origin of a uniform fullspace.\nWe apply the divergence operator to Ampere’s law:\n\\[\n\\begin{align}\n\\nabla \\cdot \\nabla \\times \\mathbf h & = \\nabla \\cdot \\mathbf j + \\partial_t \\nabla \\cdot \\mathbf d \\\\\n& = 0\n\\end{align}\n\\]\nWith \\[\n\\nabla \\cdot \\mathbf d = \\rho_E \\\\\n\\nabla \\cdot \\mathbf j = \\nabla \\cdot (\\sigma \\mathbf e) = \\nabla\\sigma \\cdot \\mathbf e + \\sigma \\nabla \\cdot \\mathbf e \\\\\n\\sigma \\nabla \\cdot \\mathbf e = \\sigma \\frac{\\rho_E}{\\varepsilon}\n\\] we obtain an initial-value problem for the charge density\n\\[\n\\frac{\\sigma}{\\varepsilon} \\rho_E + \\dot{\\rho_E} = 0.\n\\]\nIts solution is\n\\[\n\\rho_E(t) = \\rho_E(0) \\exp\\left({-\\frac{\\sigma}{\\varepsilon}t}\\right).\n\\tag{5.3}\\]\n\n5.1.1.1 Numerical experiment\nTo study the decay of a free charge denoted by an electrical charge density, we define as initial condition for \\(t=0\\) that \\(\\rho_E(0) = 1~A\\cdot s\\cdot m^{-3}\\) .\nFurther, the conductivity of the uniform fullspace is 0.01 S/m.\nWe plot the function 5.3 for a very small time window:\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nsigma_n = 0.01\nepsilon_n = 8.854e-12\n\ndef rho(t):\n  return np.exp(-sigma_n/epsilon_n * t)\n\nt_n = np.logspace(-13, -7, num=71, endpoint=True)\n\nplt.semilogx(t_n, rho(t_n))\nplt.xlabel('t in s')\nplt.ylabel(r'$\\rho_E(t)/\\rho_E(0)$')\nplt.show()\n\n\n\n\n\n\n\n\n\nBy visual inspection, after approx. 10 ns the volume charge density has dropped to zero.\nLet’s be more precise:\nWe can calculate the time at which the charge density decays to a given fraction of its initial value, e.g., to 1 ppm.\n\n\nShow the code\nfrom sympy import *\n\nt, sigma, epsilon, rho0 = symbols('t sigma epsilon rho_0', real=True)\nrhoE = symbols('rho_E')\n\nexpr = rhoE - rho0 * exp(-sigma / epsilon * t)\n\ntt = solve(expr, t)\ntt[0]\n\n\n\\(\\displaystyle \\frac{\\epsilon \\log{\\left(\\frac{\\rho_{0}}{\\rho_{E}} \\right)}}{\\sigma}\\)\n\n\nWe find that the time \\(t\\) at which a certain fraction of the initial charge density is obtained, can be calculated using\n\\[\n\\hat{t} = \\frac{\\epsilon }{\\sigma}\\log{\\left(\\frac{\\rho_{0}}{\\rho_{E}} \\right)} = -\\frac{\\epsilon }{\\sigma}\\log{\\left(\\frac{\\rho_{E}}{\\rho_{0}} \\right)}\n\\]\n\n\nShow the code\ntstar = -epsilon_n / sigma_n * np.log(1e-6)\n\n\nWith the values given above, the charge density drops to 1 ppm of its initial value after 1.22e-08 seconds.",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "pde.html#the-telegraph-equation",
    "href": "pde.html#the-telegraph-equation",
    "title": "5  Partial Differential Equations",
    "section": "5.2 The Telegraph equation",
    "text": "5.2 The Telegraph equation\nBy virtue of 5.2 we can cast the curl-curl equation 5.1 into the telegraph equation of induction, such that\n\\[\n-\\nabla^2 \\mathbf e + \\mu \\sigma \\partial_t \\mathbf e + \\mu \\varepsilon \\partial^2_{tt} \\mathbf e = \\mathbf 0.\n\\tag{5.4}\\]\n\n\n\n\n\n\nNote\n\n\n\nNote that the same PDE can be derived for the magnetic field!\n\n\nEq. 5.4 and 5.1 are second-order linear PDEs with at most second-order time derivatives. Hence, they describe wave phenomena.\n\n\n\n\n\n\nNote\n\n\n\nA second-order, linear, constant-coefficient PDE for \\(u\\) takes the general form\n\\[\nA u_{xx} + 2 B u_{xy} + C u_{yy} + D u_x + E u_y + F u + G = 0\n\\]\nThis PDE is classified as being\n\nparabolic, when \\(B^2 - AC = 0\\)\nhyperbolic, when \\(B^2 - AC &gt; 0\\)\nelliptic, when \\(B^2 - AC &lt; 0\\).\n\nIn our case, \\(x\\) plays the role of any spatial variable, and \\(t\\) plays the role of \\(y\\).\nHence, for 5.4, \\(A=-1\\), \\(E=\\mu\\sigma\\), \\(C=\\mu\\varepsilon\\), and the remaining coefficients are zero.\nChecks:\n\\(B^2 - AC = 0 - (-1 \\cdot \\mu\\varepsilon) &gt; 0\\) \\(\\to\\) PDE is hyperbolic.\n\\(B^2 - AC = 0 - (-1 \\cdot 0) = 0\\) \\(\\to\\) PDE is parabolic\nFor the elliptic PDE there are no time derivatives, we can therefore let \\(x\\) and \\(y\\) take their roles as Cartesian coordinates.\nSo, with \\(A = C = -1\\),\n\\(B^2 - AC = 0 - (-1 \\cdot -1) &lt; 0\\) \\(\\to\\) PDE is elliptic.",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "pde.html#quasi-static-approximation",
    "href": "pde.html#quasi-static-approximation",
    "title": "5  Partial Differential Equations",
    "section": "5.3 Quasi-static approximation",
    "text": "5.3 Quasi-static approximation\nIn geo-electromagnetic applications, the fields vary slowly with frequencies much less than 1 MHz. For Magnetotellurics, e.g., we use frequencies well below 100 Hz. In CSEM applications, frequencies rarely exceed 100 kHz.\nThe low frequency content of the electromagnetic field variations give reason to assume that the term associated with the second-order time derivative might be dropped.\nWe now want to provide a justification.\nThe terms in 5.1 have very different magnitudes depending on the scale of observation. To quantify the relative importance of the terms to each other, we cast the PDE into a dimensionless form.\nThis can be achieved by introducing scale lengths in space and time.\nWe introduce a typical scale length \\(L\\) and a typical period \\(T\\) and scale all spatial variables \\(\\ell\\) as well as the time \\(t\\).\nThe dimensionless variables are \\[\n\\ell' = \\ell / L \\qquad t' = t / T\n\\]\nWith the chain rule we obtain the dimensionless derivatives of a field component \\(f\\) \\[\n\\frac{\\partial f}{\\partial \\ell} = \\frac{\\partial f}{\\partial \\ell'} \\frac{\\partial \\ell'}{\\partial \\ell} = \\frac{1}{L} \\frac{\\partial f}{\\partial \\ell'}\n\\]\n\\[\n\\frac{\\partial f}{\\partial t} = \\frac{\\partial f}{\\partial t'} \\frac{\\partial t'}{\\partial t} = \\frac{1}{T} \\frac{\\partial f}{\\partial t'}\n\\]\nThis carries over to the differential operators, i.e., \\[\n\\nabla \\times \\nabla \\times \\mathbf f = \\frac{1}{L^2} \\nabla' \\times \\nabla' \\times \\mathbf f.\n\\]\nWe obtain a PDE with scaled coefficients, i.e., \\[\n\\nabla' \\times \\nabla' \\times \\mathbf e + \\eta_1 \\partial_{t'} \\mathbf e + \\eta_2 \\partial^{2}_{t't'} \\mathbf e = \\mathbf 0\n\\]\nThe coefficients are \\[\n\\begin{align}\n\\eta_1 &= \\frac{L^2}{T} \\mu \\sigma \\\\\n\\eta_2 &= \\frac{L^2}{T^2} \\mu\\varepsilon\n\\end{align}\n\\]\nWe assume that \\(\\mu=\\mu_0\\) and \\(\\varepsilon = \\varepsilon_0\\).\nThe exercise is now to show under which conditions there holds that \\(\\eta_1 \\gg \\eta_2\\).\nWhat is the physical interpretation of \\(\\eta_2\\)?\nWe see that \\[\n\\eta_2 = \\frac{L^2}{T^2} \\mu\\varepsilon = \\left( \\frac{L}{T c_0} \\right)^2.\n\\]\n\\(L/c_0\\) is the time an electromagnetic wave needs in free space to travel over the distance \\(L\\). If \\(\\eta_2\\) is small, this time is much less than a typical time \\(T\\) during which significant changes in the field occur. Such changes can be regarded as happening instantaneously over the region spanned by \\(L\\).\nUntil now, we have not considered the conductivities in that region. This can be studied with the ratio of both coefficients. We want to show that \\[\n\\frac{\\eta_1}{\\eta_2} = \\frac{\\mu\\sigma}{\\mu\\varepsilon} T = c_0^2 \\mu\\sigma T \\gg 1.\n\\]\nWe illustrate our findings and calculate meaningful values for the coefficients.\n\n\nShow the code\ndef eta1(T, L, sigma):\n  mu0 = np.pi * 4e-7\n  return L**2 / T * mu0 * sigma\n\ndef eta2(T, L):\n  mu0 = np.pi * 4e-7\n  epsilon0 = 8.854e-12\n  return L**2 / T**2 * mu0 * epsilon0\n\nT = np.logspace(-6, 3, num=91)\nL = 1e7\nplt.loglog(T, [eta2(t, L) for t in T])\nplt.xlabel('T in s')\nplt.ylabel(r'$\\eta_2$')\nplt.grid(True)\n\n\n\n\n\n\n\n\n\nIn global investigations for which \\(L \\approx 10^4\\) km, we observe that \\(\\eta_2\\) is small (less than, e.g., 0.1) for \\(T &gt; 0.1\\) seconds.\n\n\nShow the code\nplt.loglog(1 / T, [eta1(t, L, 1e-5) / eta2(t, L) for t in T])\nplt.xlabel('frequency in Hz')\nplt.ylabel(r'$\\eta_1 / \\eta_2$')\nplt.grid(True)\n\n\n\n\n\n\n\n\n\nIn the last example we have used a conductivity of \\(10^{-5}\\) S/m as a reasonable low value for minerals. We recognize that the ratio is large for frequencies less than \\(10^5\\) Hz.\nTo conclude, we can safely assume that the second term, \\(\\eta_2\\), and correspondingly the term \\(\\mu\\varepsilon\\), can be neglected for frequencies less than \\(10^5\\) Hz for the lowest reasonable value of the conductivity in the Earth. For higher conductivities, the result becomes even more pronounced.\nAs a consequence, the displacement current density in Ampere’s law can be neglected as well, such that \\[\n\\nabla \\times \\mathbf{h} = \\mathbf j\n\\]\nWe call this the quasi-static approximation of Maxwell’s equations.\nNote that this corresponds to the classical formulation of Maxwell’s equations, which have later been extended to account for displacement currents.\nThe quasi-static approximation however comes at a price: The coefficient of the second-order time derivative term of 5.1 has the physical dimension of the inverse square of the wave velocity, i.e., \\[\n\\mu\\varepsilon = \\frac{1}{c_0^2}.\n\\]\nWhen we neglect this term, we implicitly assume that \\[\n\\frac{1}{c_0^2} \\to 0,\n\\] which violates the generally recognized fact that the speed of light is finite. On the other hand, this makes it clear that changes in the fields happen everywhere at the same time.\nThe curl-curl equation for the electric field under quasi-static approximation reads \\[\n\\nabla \\times \\nabla \\times \\mathbf e + \\mu\\sigma \\partial_t \\mathbf e = \\mathbf 0\n\\tag{5.5}\\]\nWith the identity introduced earlier, we write\n\\[\n-\\nabla^2 \\mathbf e + \\mu\\sigma \\partial_t \\mathbf e = \\mathbf 0\n\\tag{5.6}\\]\nWith our definition of the Fourier transform given by 3.2 we transform the time-domain expressions into the frequency domain.\nBy doing so, we decouple the time-dependency from the PDE. For most CSEM applications, this is common practice.\nFor time-harmonic fields with an angular frequency of \\(\\omega = 2 \\pi f\\), we write \\[\n\\mathbf E(\\omega) = \\mathbf E_0 \\exp(i \\omega t)\n\\] and use the properties of the Fourier transform to equivalently formulate time derivatives. It holds that \\[\n\\partial_t \\mathbf E_0 \\exp(i \\omega t) = i \\omega \\mathbf E_0 \\exp(i \\omega t) = i \\omega \\mathbf E(\\omega).\n\\] In other words, we simply replace all first-order time-derivatives with \\(i\\omega\\), and all second-order time derivatives by \\(-\\omega^2\\).\n\n\n\n\n\n\nTime derivatives in the frequency domain\n\n\n\n\\[\n\\partial_t \\to i\\omega \\qquad \\partial^2_{tt} \\to -\\omega^2\n\\]",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "pde.html#the-vector-helmholtz-equation",
    "href": "pde.html#the-vector-helmholtz-equation",
    "title": "5  Partial Differential Equations",
    "section": "5.4 The Vector Helmholtz equation",
    "text": "5.4 The Vector Helmholtz equation\nWe use the identity 5.2 and obtain \\[\n-\\nabla^2 \\mathbf E + i \\omega \\mu \\sigma \\mathbf E = \\mathbf 0\n\\]\n\n\n\n\n\n\nNotation\n\n\n\nIn what follows, we use capital letters for fields in the frequency domain, e.g., \\(\\mathbf E\\).\nIn the time domain, the fields are typeset in small letters, e.g., \\(\\mathbf e\\).\n\n\nMany textbooks use the notation \\[\n\\nabla^2 \\mathbf e - i \\omega \\mu \\sigma \\mathbf e = \\mathbf 0\n\\] with the abbreviation \\[\n\\nabla^2 \\mathbf e + k^2 \\mathbf e = \\mathbf 0,\n\\tag{5.7}\\] where \\[\nk^2 = - i \\omega \\mu \\sigma.\n\\]\nEquation 5.7 is referred to as the homogeneous Helmholtz equation.\nThe coefficient \\(k\\) is often called the wave number or wave propagation constant.\n\n\n\n\n\n\nWarning\n\n\n\nNote that \\(k^2\\) is a complex-valued quantity. The roots of \\(k^2\\) must be chosen carefully.\n\n\n\n5.4.1 The roots of \\(k^2\\)\nWe consider a Helmholtz equation for a plane wave \\[\n\\mathbf H = [1, 0, 0]^\\top \\text{ in } z &lt; 0\n\\] with a time dependency of \\(\\exp(i \\omega t)\\). \\(\\mathbf H\\) is a magnetic field, which is uniform in any horizontal plane, and exhibits only a horizontal component.\nInside the conducting Earth, the magnetic field will be attenuated due to energy dissipation. This can be modelled using the Helmholtz equation.\nThe magnetic field in \\(z \\ge 0\\) is a solution of the scalar Helmholtz equation \\[\n\\partial^2_{zz} H_x + k^2 H_x = 0\n\\tag{5.8}\\] where \\[\nH_x(z) = H_x(0) e^{-i k z}.\n\\tag{5.9}\\] The propagation inside the Earth depends on \\(k^2\\). However, in 5.9 we need the root of \\(k^2\\).\nPhysical reasoning gives a hint on which of both signs of \\(\\pm k\\) has to be used.\nIn the following we choose the proper sign by numerical evidence.\nWe use sympy to exlore the problem:\n\n5.4.1.1 Symbolic representation of \\(k^2\\)\n\n\nShow the code\nimport sympy\nfrom IPython.display import display, Math \ninit_printing(use_latex='mathjax', latex_mode='equation')\n\nalpha, beta, z = symbols(r'\\alpha \\beta z', real=True)\nomega, sigma, mu = symbols(r'\\omega \\sigma \\mu', real=True, positive=True)\n\n\nWe make the ansatz \\[\nk^2 = (\\alpha - i \\beta)^2\n\\] Expansion and separation of real and imaginary parts yiels the two equations \\[\n\\alpha^2 - \\beta^2 = 0\n\\] and \\[\n-2 \\alpha \\beta = - \\omega \\mu \\sigma.\n\\]\n\n\nShow the code\nexpr = expand((alpha - I * beta)**2)\nre(expr)\n\n\n\\[\\begin{equation}\\alpha^{2} - \\beta^{2}\\end{equation}\\]\n\n\n\n\nShow the code\nk2 = -I * omega * mu * sigma\n\nex = re(expr).subs(beta, solve([im(expr) - im(k2)], beta)[beta])\n# solve([im(expr) - im(k2)], beta)[beta]\n\nsol = solve(ex, alpha)\nsol\n\n\n\\[\\begin{equation}\\left[ - \\frac{\\sqrt{2} \\sqrt{\\mu} \\sqrt{\\omega} \\sqrt{\\sigma}}{2}, \\  \\frac{\\sqrt{2} \\sqrt{\\mu} \\sqrt{\\omega} \\sqrt{\\sigma}}{2}\\right]\\end{equation}\\]\n\n\nWe see, that \\[\n\\alpha = \\pm \\sqrt{\\frac{\\omega \\mu \\sigma}{2}} = \\beta\n\\] It remains to decide on the correct sign of \\(\\alpha\\) and \\(\\beta\\).\nWe model the field component \\(H_x(z)\\) as a function of \\(\\alpha\\) and \\(\\beta\\). With \\(k = \\pm (\\alpha - i\\beta)\\) we get \\[\nH_x(z) = e^{-i k z} e^{+i \\omega t} = e^{-i \\alpha z} e^{-\\beta z} e^{+i \\omega t}.\n\\]\nOnly for \\(\\beta &gt; 0\\) we observe an exponential decay with depth to assure that \\(H_x(z) \\to 0\\) for \\(z \\to \\infty\\).\nWhen \\(\\beta = 0\\) (no damping), we observe a pure wave propagation.\nIn this case, \\[\nH_x(z) = e^{-i \\alpha z} e^{+i \\omega t} = e^{-i (\\alpha z - \\omega t)} = e^{-i \\varphi}\n\\]\nwith \\(\\varphi = \\alpha z - \\omega t\\) the phase of the wave.\nTo obtain the direction of wave propagation, we form the time dericative of the plane of constant phase, i.e., \\[\nz = \\frac{1}{\\alpha} (\\varphi + \\omega t)\n\\] and \\[\nc = \\dot{z} = \\frac{\\omega}{\\alpha}\n\\] The wave propagates in positive \\(z\\)-direction (with a positive wave velocity \\(c\\)) only when \\(\\alpha &gt; 0\\).\n\n\n\n\n\n\nNote\n\n\n\nSummary:\n\\[\n\\alpha = \\beta = \\sqrt{\\frac{\\omega \\mu \\sigma}{2}}\n\\]\n\n\n\n\n5.4.1.2 Skin depth\nIn the previous section we have seen that the electrical conductivity of the halfspace gives rise to an exponential decay of the wave amplitude.\nWe are now able to define a typical scale length which helps to understand the physical phenomena in different depths.\nRecall that \\(\\exp(-\\beta z) \\to 0\\) for \\(z \\to +\\infty\\) for \\(\\beta &gt; 0\\).\nThen there exists a depth \\(z = \\frac{1}{\\beta}\\) where the amplitude of the wave drops to \\(\\exp(-1)\\) of its surface amplitude.\nThis depth is called the electromagnetic skin depth \\(\\tau\\).\nAt this depth, the wave has lost 63 % of its surface amplitude.\n\\[\n\\tau = \\frac{1}{\\beta} = \\sqrt{\\frac{2}{\\omega \\mu \\sigma}} \\approx 503 \\sqrt{\\rho / f}\n\\]\nThe last part of the equation approximates the skin depth. With \\(\\rho\\) given in \\(\\Omega \\cdot m\\) and \\(f\\) given in Hz, this equation returns the skin depth \\(\\tau\\) in meters.\nThe following animation shows the real and imaginary part of the magnetic field for a frequency of 1 Hz in a uniform halfspace with a resistivity of 100 \\(\\Omega \\cdot m\\). The red and green horizontal lines indicate the skin depth and the wave length, resp.\nCheck: For \\(\\rho = 100~\\Omega \\cdot m\\) and \\(f = 1\\) Hz, the skin depth is approximately \\[\n\\tau = 503 \\sqrt{\\rho / f} \\approx 5.03 \\text{ km.}\n\\]\n\\[\n\\lambda = 2 \\pi \\tau \\approx 31.6 \\text{ km.}\n\\]\n\n\n\n\n\n\nPython code\n\n\n\n\n\nThis is the Python code that you can use to create the following animation:\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.animation import FuncAnimation\n\ndef h(z, a, b, w, t):\n    return np.exp(-1j * a * z) * np.exp(-b * z) * np.exp(1j * w * t)\n\nT = 1.0\nw = 2 * np.pi / T \nsigma = 1e-2\nmu = np.pi * 4e-7\n\nkk = np.sqrt(w * mu * sigma / 2)\na = kk\nb = kk\nzair = np.arange(start=-10000, stop=0, step=100)\nzz = np.arange(start=0, stop=6e4, step=600)\ntau = 1.0 / kk\n\nfig, ax = plt.subplots(figsize=(4, 6), layout='constrained')\n\ndef update(frame):\n    ax.clear()\n    t = frame * T / 100.0\n    ax.plot([np.real(np.exp(1j * w * t)) for _ in zair], zair, color='blue', label='', zorder=1)\n    ax.plot([np.real(h(z, a, b, w, t)) for z in zz], zz, color='blue', label='Re', zorder=2)\n    ax.plot([np.imag(h(z, a, b, w, t)) for z in zz], zz, label='Im', zorder=3)\n    ax.fill_betweenx(zz, -np.exp(-b * zz), np.exp(-b * zz), color='grey', alpha=0.5, label='')\n    zp = w * t / a if a &gt; 0.0 else np.max(zz) + w * t / a\n    ax.scatter(np.real(h(zp, a, b, w, t)), zp, marker='*', color='black', label='phase')\n    ax.axhline(y=tau, color='red', label='τ')\n    ax.axhline(y=2 * np.pi * tau, color='green', label='λ')\n    ax.set_ylabel('Depth in km')\n    ax.set_xlabel('Normalized amplitude')\n    ax.set_xlim(-1.0, 1.0)\n    ax.set_ylim(min(zair), max(zz))\n    ax.invert_yaxis()\n    ax.legend(loc='lower left')\n\nani = FuncAnimation(fig, update, frames=100, interval=50)\n\nani.save('animation.gif')",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Partial Differential Equations</span>"
    ]
  },
  {
    "objectID": "mtfields.html",
    "href": "mtfields.html",
    "title": "6  Plane waves above and inside a homogeneous Earth",
    "section": "",
    "text": "6.1 Visualization\nWe illustrate our results with a simple example of a uniform halfspace with a conductivity of 0.01 S/m and a frequency of 10 Hz.\nShown are real (Re) and imaginary (Im) part of the fields along with their magnitude (Abs) as a function of depth.\nClearly visible is the exponential decay with depth.\nShow the code\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nf = 10\nomega = 2 * np.pi * f\nsigma = 0.01\n\nz = np.arange(-1000, 10001, 10)\n\ndef h(omega, sigma, z):\n    k = np.sqrt(-1j * omega * np.pi * 4e-7 * sigma)\n    if z &lt; 0:\n        H = 1 + 1j * 0\n    if z &gt;= 0:\n        H = np.exp(-1j * k * z)\n    return H\n\ndef e(omega, sigma, z):\n    k = np.sqrt(-1j * omega * np.pi * 4e-7 * sigma)\n    if z &lt; 0:\n        E = -1j * k / sigma * (1 - 1j * k * z)\n    if z &gt;= 0:\n        E = -1j * k / sigma * np.exp(-1j * k * z)\n    return E\n\nH = [h(omega, sigma, zz) for zz in z]\nE = [e(omega, sigma, zz) for zz in z]\nH0 = h(omega, sigma, 0.0)\nE0 = e(omega, sigma, 0.0)\nIn our example, the skin depth is 1590.63 m.\nShow the code\nfig, ax = plt.subplots(figsize=(4, 4), layout='constrained')\nax.plot(np.real(E / E0), z, label='Re')\nax.plot(np.imag(E / E0), z, label='Im')\nax.plot(np.abs(E / E0), z, label='Abs')\nax.axhspan(z[0], 0.0, facecolor='lightblue', alpha=0.4)\nax.axhspan(0.0, z[-1], facecolor='lightgreen', alpha=0.4)\nax.invert_yaxis()\nax.set_ylim((z[-1], z[0]))\nax.set_ylabel('depth in m')\nax.set_xlabel(r'$E(z)/E(0)$')\nax.set_title('Normalized electric field')\nax.grid(True)\nax.legend(loc='lower right')\nShow the code\nfig, ax = plt.subplots(figsize=(4, 4), layout='constrained')\nax.plot(np.real(H / H0), z, label='Re')\nax.plot(np.imag(H / H0), z, label='Im')\nax.plot(np.abs(H / H0), z, label='Abs')\nax.axhspan(z[0], 0.0, facecolor='lightblue', alpha=0.4)\nax.axhspan(0.0, z[-1], facecolor='lightgreen', alpha=0.4)\nax.invert_yaxis()\nax.set_ylim((z[-1], z[0]))\nax.set_ylabel('depth in m')\nax.set_xlabel(r'$H(z)/H(0)$')\nax.set_title('Normalized magnetic field')\nax.grid(True)\nax.legend(loc='lower right')",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Plane waves above and inside a homogeneous Earth</span>"
    ]
  },
  {
    "objectID": "mtfields.html#impedance-and-apparent-resistivity",
    "href": "mtfields.html#impedance-and-apparent-resistivity",
    "title": "6  Plane waves above and inside a homogeneous Earth",
    "section": "6.2 Impedance and apparent resistivity",
    "text": "6.2 Impedance and apparent resistivity\nWe define the magnetotelluric impedance as \\[\nZ(\\omega) = \\frac{ \\mathbf e_h \\cdot \\mathbf E }{(\\mathbf e_h \\times \\mathbf e_z) \\cdot \\mathbf H } = \\frac{ E_x }{ H_y} = -\\frac{ E_y }{H_x }\n\\] where \\(\\mathbf e_h\\) is an arbitrary horizontal Cartesian unit vector, and \\(\\mathbf e_z\\) is the vertical Cartesian unit vector.\nOn the surface of a halfspace, we can measure the surface impedance \\[\nZ_s = Z(\\omega),\n\\] which in case of a uniform halfspace is identical to the intrinsic impedance \\[\nZ_1 = \\frac{ \\omega \\mu_0 }{ k_1 } = Z_s.\n\\] Here, \\(k_1^2 = -i\\omega\\mu_0\\sigma_1\\) is the wave propagation constant of the first (however infinite in its vertical extent) layer.\nFrom \\(Z_s\\) we can infer the apparent resistivity \\[\n\\rho_a = \\frac{ 1 }{ \\omega \\mu_0} |Z_s|^2\n\\] and the phase \\[\n\\varphi = \\arctan \\frac{ \\mathrm{Im}(Z_s) }{\\mathrm{Re}(Z_s) }.\n\\]\n\n6.2.1 Example\n\nsigma = 0.01\nf = 100.0\nmu0 = np.pi * 4e-7\nomega = 2 * np.pi * f\nk = np.sqrt(-1j * omega * mu0 * sigma)\nHx = 1.0\nEy = -1j * k / sigma\nZs = Ey / Hx\n\nrhoa = lambda Z, f: np.abs(Z)**2 / ( 2 * np.pi * f * mu0)\nphi = lambda Z: np.arctan(np.imag(Z) / np.real(Z)) * 180 / np.pi\n\nFor our example, the apparent resistivity is 100.0 \\(\\Omega \\cdot m\\). The phase angle is 45.0 degrees.\n\n\n\n\n\n\nNote\n\n\n\nNote the sign of \\(Z_s\\), which depends on the choice of the horizontal field components.\nLet’s check the result of the cross product \\(\\mathbf e_h \\times \\mathbf e_z\\):\n\\[\n\\begin{bmatrix}\n1 \\\\ 0 \\\\ 0\n\\end{bmatrix} \\times\n\\begin{bmatrix}\n0 \\\\ 0 \\\\ 1\n\\end{bmatrix} =\n\\begin{bmatrix}\n0 \\\\ -1 \\\\ 0\n\\end{bmatrix} \\quad\\text{with } \\mathbf e_h = \\mathbf e_x\n\\]\n\\[\n\\begin{bmatrix}\n0 \\\\ 1 \\\\ 0\n\\end{bmatrix} \\times\n\\begin{bmatrix}\n0 \\\\ 0 \\\\ 1\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 \\\\ 0 \\\\ 0\n\\end{bmatrix} \\quad\\text{with } \\mathbf e_h = \\mathbf e_y\n\\]\n\n\nIn the inhomogeneous case, i.e., when the conductivity of the halfspace is not uniform, the apparent resistivity and phase generally vary with frequency.\nThis can be visualized using sounding curves of \\(\\rho_a\\) vs. period \\(T = 1/f\\) or \\(\\varphi\\) vs. \\(T\\).",
    "crumbs": [
      "Maxwell's equations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Plane waves above and inside a homogeneous Earth</span>"
    ]
  },
  {
    "objectID": "potentials.html",
    "href": "potentials.html",
    "title": "7  Sources in unbounded media",
    "section": "",
    "text": "7.1 Polarization vectors\nIn the absence of matter, we observe that \\[\n\\mathbf d - \\varepsilon_0 \\mathbf e = \\mathbf 0\n\\] and \\[\n\\mu_0^{-1} \\mathbf b - \\mathbf h = \\mathbf 0.\n\\] When the differences are non-zero, then we observe the response of matter. We define the electrical polarization \\(\\mathbf p\\) \\[\n\\mathbf p = \\mathbf d - \\varepsilon_0 \\mathbf e\n\\] and the magnetic polarization or magnetization \\(\\mathbf m\\) \\[\n\\mathbf m = \\mu_0^{-1} \\mathbf b - \\mathbf h\n\\] The polarization vectors \\(\\mathbf p\\) and \\(\\mathbf m\\) are parallel and proportional to \\(\\mathbf e\\) and \\(\\mathbf h\\), resp.\nWe are able to quantify the polarization properties by the electrical susceptibility \\(\\chi_e\\) and magnetic susceptibility \\(\\chi_m\\). The latter is often referred to as the magnetic susceptibility \\(\\kappa\\).\nWe define \\[\n\\mathbf p := \\chi_e \\varepsilon_0 \\mathbf e = \\mathbf d - \\varepsilon_0 \\mathbf e\n\\] and likewise \\[\n\\mathbf m := \\chi_m \\mathbf h = \\mu_0^{-1} \\mathbf b - \\mathbf h.\n\\] It follows for the relative dielectric permittivity \\[\n\\varepsilon_r = 1 + \\chi_e\n\\] and for the relative magnetic permeability \\[\n\\mu_r = 1 + \\chi_m = 1 + \\kappa.\n\\]\nTo implement technical sources, we separate the polarization into induced (superscript \\(i\\)) and external (superscript \\(s\\)) contributions to the observed fields: \\[\n\\mathbf p = \\mathbf p^i + \\mathbf p^s = \\mathbf d - \\varepsilon_0 \\mathbf e.\n\\] Then, \\[\n\\mathbf d = [\\underbrace{\\varepsilon_0 \\mathbf e}_\\text{free space} + \\underbrace{\\mathbf p^i}_\\text{matter}] + \\mathbf p^s\n\\] and \\[\n\\mathbf b = [\\underbrace{\\mu_0 \\mathbf h}_\\text{free space} + \\underbrace{\\mu_0 \\mathbf m^i}_\\text{matter}] + \\mu_0 \\mathbf m^s\n\\]\nWith the introduction of the polarization vectors, we are now able to augment Maxwell’s equations, such that \\[\n\\begin{align}\n\\nabla \\times \\mathbf h & = \\mathbf j + \\varepsilon \\partial_t \\mathbf e + \\partial_t \\mathbf p^s \\\\\n\\nabla \\times \\mathbf e & = \\phantom{\\mathbf j} -\\mu \\partial_t \\mathbf h - \\mu_0 \\partial_t \\mathbf m^s\n\\end{align}\n\\]\nWe define the source current densities in the magnetic and electric case as \\[\n\\mathbf j_m^s := \\mu_0 \\partial_t \\mathbf m^s\n\\] and \\[\n\\mathbf j_e^s := \\phantom{\\mu_0} \\partial_t \\mathbf p^s .\n\\]\nNow, we extend our definitions to the frequency domain: \\[\n\\mathbf J_m^s := i \\omega \\mu_0 \\mathbf M^s\n\\] and \\[\n\\mathbf J_e^s := i \\omega \\mathbf P^s .\n\\]",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "potentials.html#polarization-vectors",
    "href": "potentials.html#polarization-vectors",
    "title": "7  Sources in unbounded media",
    "section": "",
    "text": "Example\n\n\n\nWe consider a magnetic dipole at the point \\(\\mathbf r_0 = [0, 0, -h]^\\top, h &gt; 0\\).\nThe point of observation is at \\(\\mathbf r = [x, y, z]^\\top\\).\nThe location of the dipole can now be pinned to \\(\\mathbf r_0\\) using a Dirac delta function.\nWe obtain \\[\n\\mathbf M^s(\\mathbf r) = \\mathbf m \\, \\delta(\\mathbf r - \\mathbf r_0)\n\\] with \\(\\mathbf m\\) the oriented magnetic dipole moment. The dipole moment has the physical dimension of \\([\\mathbf m] =\\) A\\(\\cdot m^2\\). It can be interpreted as a current \\(I\\) measured in A enclosing a surface measured in \\(m^2\\).\nAs a vector quantity, the dipole moment has a direction. Its direction is given by the unit vector normal to the surface of the enclosed area.\nA useful special case arises when the dipole is aligned with one of the Cartesian axes.\nThis way, we can define a vertical or horizontal dipole.",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "potentials.html#electromagnetic-potentials",
    "href": "potentials.html#electromagnetic-potentials",
    "title": "7  Sources in unbounded media",
    "section": "7.2 Electromagnetic potentials",
    "text": "7.2 Electromagnetic potentials\nLet’s assume that electric and magnetic fields originate from either a magnetic or an electric source, i.e., \\[\n\\begin{align}\n\\mathbf E & = \\mathbf E_m + \\mathbf E_e \\\\\n\\mathbf H & = \\mathbf H_m + \\mathbf H_e\n\\end{align}\n\\] When \\(\\mathbf J_e \\equiv 0\\), then we only observe the set of fields \\([\\mathbf E_m, \\mathbf H_m]\\).\nWhen \\(\\mathbf J_m \\equiv 0\\), then we only observe the set of fields \\([\\mathbf E_e, \\mathbf H_e]\\).\nThe two sets are disjoint. We insert into Maxwell’s equations \\[\n\\begin{align}\n\\nabla \\times \\mathbf E_m & = -i \\omega \\mu \\mathbf H_m \\textcolor{red}{- \\mathbf J_m^s} \\\\\n\\nabla \\times \\mathbf H_m & = (\\sigma + i \\omega \\varepsilon) \\mathbf E_m\n\\end{align}\n\\]\n\\[\n\\begin{align}\n\\nabla \\times \\mathbf E_e & = -i \\omega \\mu \\mathbf H_e  \\\\\n\\nabla \\times \\mathbf H_e & = (\\sigma + i \\omega \\varepsilon) \\mathbf E_e \\textcolor{red}{+ \\mathbf J_e^s}\n\\end{align}\n\\]\nNow we apply the divergence to all of the above equations. Here we employ the identity \\[\n\\nabla \\cdot (\\nabla \\times \\mathbf F) = 0,\n\\tag{7.1}\\] such that, e.g., \\[\n\\underbrace{\\nabla \\cdot (\\nabla \\times \\mathbf E_m)}_{=0}  = -i \\omega \\mu \\nabla \\cdot \\mathbf H_m - \\nabla \\cdot \\mathbf J_m^s.\n\\] We obtain \\[\n\\begin{align}\n\\nabla \\cdot \\mathbf H_m & = -\\frac{ \\nabla \\cdot \\mathbf J_m^s }{i \\omega \\mu } \\\\\n\\nabla \\cdot \\mathbf E_e & = -\\frac{ \\nabla \\cdot \\mathbf J_e^s }{\\sigma + i \\omega \\varepsilon } \\\\\n\\nabla \\cdot \\mathbf H_e & = 0 \\\\\n\\nabla \\cdot \\mathbf E_m & = 0.\n\\end{align}\n\\] Since the divergence of \\(\\mathbf H_e\\) and \\(\\mathbf E_m\\) are zero, we can express both fields by the curl of an arbitrary vector field according to 7.1. However, this vector field must fulfill Maxwell’s equations. The following ansatz employing the vector potentials \\(\\mathbf F\\) and \\(\\mathbf A\\) meets this requirement: \\[\n\\begin{align}\n\\mathbf E_m & = -\\nabla \\times \\mathbf F \\\\\n\\mathbf H_e & = \\phantom{-} \\nabla \\times \\mathbf A.\n\\end{align}\n\\] It follows \\[\n\\begin{align}\n\\nabla \\times \\mathbf H_m & = -(\\sigma + i \\omega \\varepsilon) \\nabla \\times \\mathbf F \\\\\n\\nabla \\times \\mathbf E_e & = -i \\omega \\mu \\nabla \\times \\mathbf A\n\\end{align}\n\\] from which we obtain \\[\n\\begin{align}\n\\mathbf H_m & = -(\\sigma + i \\omega \\varepsilon) \\mathbf F - \\nabla V \\\\\n\\mathbf E_e & = -i \\omega \\mu \\mathbf A - \\nabla U\n\\end{align}\n\\] because of \\[\n\\nabla \\times \\nabla u = \\mathbf 0.\n\\] The scalar potentials \\(V\\) and \\(U\\) are referred to as magnetic and electrical scalar potential, resp.",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "potentials.html#the-curl-curl-equation-for-the-potentials",
    "href": "potentials.html#the-curl-curl-equation-for-the-potentials",
    "title": "7  Sources in unbounded media",
    "section": "7.3 The curl-curl equation for the potentials",
    "text": "7.3 The curl-curl equation for the potentials\nLet’s insert the potentials into Maxwell’s equations.\n\\[\n\\begin{align}\n\\mathbf E_m & = - \\nabla \\times \\mathbf F \\\\\n\\nabla \\times \\mathbf E_m & = - \\nabla \\times \\nabla \\times \\mathbf F && = -i \\omega \\mu \\textcolor{red}{\\mathbf H_m} - \\mathbf J^s_m \\\\\n&   && = i \\omega \\mu \\textcolor{red}{(\\sigma + i \\omega \\varepsilon) \\mathbf F} + i \\omega \\mu \\textcolor{red}{\\nabla V} - \\mathbf J^s_m\n\\end{align}\n\\]\n\\[\n\\begin{align}\n\\mathbf H_e & = \\phantom{-} \\nabla \\times \\mathbf A \\\\\n\\nabla \\times \\mathbf H_e & = \\phantom{-} \\nabla \\times \\nabla \\times \\mathbf A && = (\\sigma + i \\omega \\varepsilon) \\textcolor{red}{\\mathbf E_e} + \\mathbf J^s_e \\\\\n&   && = \\textcolor{red}{-i \\omega \\mu} (\\sigma + i \\omega \\varepsilon) \\textcolor{red}{\\mathbf A} - i \\omega \\mu \\textcolor{red}{\\nabla U} + \\mathbf J^s_e\n\\end{align}\n\\]\nWe use the vector identity 5.2 and obtain\n\\[\n\\begin{align}\n-\\nabla^2 \\mathbf F + \\nabla \\nabla \\cdot \\mathbf F + i \\omega \\mu (\\sigma + i \\omega \\varepsilon) \\mathbf F + i \\omega \\mu \\nabla V & = + \\mathbf J^s_m \\\\\n-\\nabla^2 \\mathbf A + \\nabla \\nabla \\cdot \\mathbf A + i \\omega \\mu (\\sigma + i \\omega \\varepsilon) \\mathbf A + i \\omega \\mu \\nabla U & = + \\mathbf J^s_e\n\\end{align}\n\\]",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "potentials.html#the-vector-helmholtz-equations-for-the-potentials",
    "href": "potentials.html#the-vector-helmholtz-equations-for-the-potentials",
    "title": "7  Sources in unbounded media",
    "section": "7.4 The vector Helmholtz equations for the potentials",
    "text": "7.4 The vector Helmholtz equations for the potentials\nQuestion: How to get rid of \\(V\\) and \\(U\\)?\nWe choose the arbitrary scalar potential \\(V, U\\) such that it cancels with the expression \\(\\nabla \\cdot \\mathbf F\\) and \\(\\nabla \\cdot \\mathbf A\\), resp. \\[\n\\begin{align}\n\\nabla \\nabla \\cdot \\mathbf F & = - i \\omega \\mu \\nabla V \\\\\n\\nabla \\cdot \\mathbf F & = - i \\omega \\mu V\n\\end{align}\n\\] and obtain \\[\n-\\nabla^2 \\mathbf F + i \\omega \\mu (\\sigma + i \\omega \\varepsilon) \\mathbf F = + \\mathbf J^s_m.\n\\] or short \\[\n\\nabla^2 \\mathbf F + k^2 \\mathbf F = -\\mathbf J^s_m, \\qquad k^2 = -i \\omega \\mu (\\sigma + i \\omega \\varepsilon).\n\\]\n\n\n\n\n\n\nSelf study\n\n\n\nRepeat the steps above for the case of \\(\\mathbf A\\).\n\n\n\n\n\n\n\n\nSummary\n\n\n\nWe have eliminated the scalar potentials \\(V\\) and \\(U\\) by use of the Lorenz gauge.\nThe vector potentials are solutions to \\[\n\\nabla^2 \\mathbf F + k^2 \\mathbf F  = -\\mathbf J^s_m\n\\tag{7.2}\\] and \\[\n\\nabla^2 \\mathbf A + k^2 \\mathbf A = -\\mathbf J^s_e.\n\\tag{7.3}\\]\nThese equations are called inhomogeneous Helmholtz equations.\nNote that the vector potentials are aligned with the direction of the source current densities!",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "potentials.html#solutions-of-the-inhomogeneous-helmholtz-equation",
    "href": "potentials.html#solutions-of-the-inhomogeneous-helmholtz-equation",
    "title": "7  Sources in unbounded media",
    "section": "7.5 Solutions of the inhomogeneous Helmholtz equation",
    "text": "7.5 Solutions of the inhomogeneous Helmholtz equation\nWe now want to find solutions to the inhomogeneous vector Helmholtz equations.\nLet’s consider the potential \\(\\mathbf A\\) 7.3.\nTo obtain a solution, we take the following steps:\n\ntransform the expressions into the Fourier wave number domain\nsolve the algebraic equation\ntransform back into space domain\n\nFirst, we need a useful definition of the Fourier transform. We follow a similar notation like that given in 3.2, but instead of time and angular frequency we choose as variables the Cartesian coordinates \\(x, y, z\\) and the corresponding wave numbers \\(k_x, k_y, k_z\\).\nWe define the 3-D Fourier transform pair \\[\n\\begin{align}\n\\tilde{\\mathbf A}(k_x, k_y, k_z)\n    & = \\iiint\\limits_{-\\infty}^\\infty \\mathbf A(x,y,z) e^{-i(k_x x + k_y y + k_z z)}\\, \\mathrm d x \\mathrm d y \\mathrm d z \\\\\n\\mathbf A(x,y,z)  & = \\frac{ 1 }{(2 \\pi)^3 } \\iiint\\limits_{-\\infty}^\\infty \\tilde{\\mathbf A}(k_x, k_y, k_z) e^{+i(k_x x + k_y y + k_z z)} \\, \\mathrm d k_x \\mathrm d k_y \\mathrm d k_z\n\\end{align}\n\\]\nAlso required are the differentiation, convolution, and linearity properties of the Fourier transform.\nWe recognize that in a Cartesian coordinate system \\[\n\\nabla^2 := \\partial^2_{xx} + \\partial^2_{yy} + \\partial^2_{zz}\n\\] and therefore \\[\n\\partial^2_{xx} e^{-i k_x x} = -k_x^2 e^{-i k_x x} \\text{ etc.}\n\\]\nAfter transformation of 7.2 into the wave number domain, we have \\[\n(-k_x^2 - k_y^2 - k_z^2 + k^2) \\tilde{\\mathbf A} = -\\tilde{\\mathbf J}^s_m.\n\\] Recall that \\(k^2 = -i \\omega \\mu (\\sigma + i \\omega \\varepsilon)\\).\nAfter rearranging we obtain \\[\n\\tilde{\\mathbf A} = \\tilde{\\tilde{G}} \\tilde{\\mathbf J}^s_m\n\\tag{7.4}\\] with the scalar function \\[\n\\tilde{\\tilde{G}} = (k_x^2 + k_y^2 + k_z^2 - k^2)^{-1}.\n\\] \\(\\tilde{\\tilde{G}}\\) is the 3-D Fourier transform of what we will later refer to as Green’s function.\nWe can obtain \\(\\mathbf A\\) directly in the spatial domain by evaluating a 3-D convolution integral, since 7.4 is a multiplication in the wave number domain by exploiting the convolution property of the Fourier transform. Unfortunately, we still have not found an expression for \\(G\\).\nTo this end, let’s consider a PDE similar to 7.3. The differences are important: First, the solution to the PDE is a scalar function \\(G\\), second, the right-hand side of the equation is a Dirac impulse in space.\nWe depart from \\[\n\\nabla^2 G + k^2 G = -\\delta(x) \\delta(y) \\delta(z)\n\\tag{7.5}\\]\nWe take steps 1 and 2 as outlined above and obtain \\[\n\\tilde{\\tilde{G}} = (k_x^2 + k_y^2 + k_z^2 - k^2)^{-1}.\n\\] To find \\(G\\), we first transform back into space domain w.r.t. \\(z\\) and obtain \\[\n\\tilde{G(k_x, k_y, z)} = \\frac{ 1 }{ 2 \\pi} \\int\\limits_{-\\infty}^{\\infty}\n\\tilde{\\tilde{G}} e^{i k_z z} \\, \\mathrm d k_z = \\frac{ e^{-u|z|} }{ 2 u}\n\\] with \\(u = \\sqrt{k_x^2 + k_y^2 - k^2}\\).\nNext, we carry out a 2-D Fourier transform w.r.t. \\(x\\) and \\(y\\): \\[\nG(x,y,z) = \\frac{ 1 }{ 4 \\pi^2} \\iint\\limits_{-\\infty}^{\\infty} \\frac{ e^{-u|z|} }{ 2 u}\ne^{i (k_x x + k_y y)} \\, \\mathrm d k_x  \\mathrm d k_y\n\\]\nSince \\(u\\) is an axisymmetric function of \\(k_x\\) and \\(k_y\\), we use of the following Hankel transform: \\[\n\\frac{ 1 }{ 4 \\pi^2} \\iint\\limits_{-\\infty}^{\\infty} F(k_x^2 + k_y^2)\ne^{i (k_x x + k_y y)} \\, \\mathrm d k_x  \\mathrm d k_y\n=\n2 \\pi \\int\\limits_0^\\infty F(\\lambda) J_0(\\lambda R) \\lambda \\, \\mathrm d \\lambda,\n\\] where \\[\n\\lambda^2 = k_x^2 + k_y^2\n\\] the horizontal wave number, \\[\nR^2 = x^2 + y^2\n\\] the radial distance from the \\(z\\)-axis, and \\[\nF :=   \\frac{ e^{-u|z|} }{ 2 u}, \\quad u^2 = \\lambda^2 - k^2.\n\\]\nFinally, we obtain the integral \\[\nG(R, z) = \\frac{ 1 }{ 4 \\pi } \\int\\limits_0^\\infty \\frac{ \\lambda  }{ u} e^{-u|z|} J_0(\\lambda R) \\, \\mathrm d \\lambda\n\\] This is the Sommerfeld integral, from which we get with \\(r^2 = R^2 + z^2\\) the function \\[\nG(r) = \\frac{ 1 }{ 4 \\pi r} e^{- i k r}.\n\\]\nThis is the Green’s function for the uniform conductive fullspace in the frequenccy domain.",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "potentials.html#the-greens-function",
    "href": "potentials.html#the-greens-function",
    "title": "7  Sources in unbounded media",
    "section": "7.6 The Green’s function",
    "text": "7.6 The Green’s function\nThe Green’s function or the impulse response of the conductive fullspace in the frequency domain is\n\\[\nG(r, \\omega) = \\frac{1}{4 \\pi r} e^{- i k r} = \\frac{1}{4 \\pi r} e^{- i r \\sqrt{\\omega^2 \\mu \\varepsilon - i \\omega \\mu \\sigma}}.\n\\] To obtain the time-domain response \\(g(r,t)\\), we apply the inverse Fourier transform, i.e., \\[\ng(r, t) = \\frac{1}{2 \\pi} \\frac{1}{4 \\pi r} \\int\\limits_{-\\infty}^\\infty\ne^{- i r \\sqrt{\\omega^2 \\mu \\varepsilon - i \\omega \\mu \\sigma}}\ne^{i \\omega t}\n\\mathrm{d}\\omega.\n\\]\n\n7.6.1 Free space\nFirst, let’s restrict to the free space case, where \\(\\sigma=0\\). We obtain \\[\ng(r,t) = \\frac{1}{8 \\pi^2 r} \\int \\limits_{-\\infty}^\\infty\ne^{i \\omega (t \\pm r \\sqrt{\\mu \\varepsilon}) } \\mathrm{d}\\omega.\n\\] To obtain \\(g\\), we need the shifting property of the Fourier transform: \\[\n\\delta(t \\pm t') =  \\frac{1}{2 \\pi} \\int \\limits_{-\\infty}^\\infty\ne^{i \\omega (t \\pm t')}\n\\mathrm{d}\\omega\n\\] It follows that \\[\ng(r, t) = \\frac{1 }{4 \\pi r}  \\delta(t - r / c)\n\\] The sign is chosen such that causality is guaranteed, i.e., \\[\ng(r, t) = 0 \\text{ for } t &lt; 0.\n\\] The result obtained above is called the retarded potential.\n\n\n7.6.2 Quasi-static approximation\nFor moderate to high conductivities and/or low frequencies, we have introduced the quasi-static approximation, which justifies that displacement currents may safely be neglected in geo-electromagnetic applications.\nWe start from the Green’s function under quasi-static approximation: \\[\nG(r, \\omega) = \\frac{1}{4 \\pi r} e^{-i r \\sqrt{-i \\omega \\mu \\sigma}} =\n\\frac{1}{4 \\pi r} e^{-r \\sqrt{i \\omega \\mu \\sigma}}\n\\] To obtain the time-domain Green’s function, we apply the Laplace transform, which is as an integral transform similar to the Fourier transform, except that the former is restricted to transformations of functions of \\(t\\) with \\(t \\ge 0\\). This is in accordance to the causality requirement stated above.\nWith the Laplace variable \\(s := i \\omega\\) we rewrite \\[\nG(r, s) = \\frac{1}{4 \\pi r} e^{-r \\sqrt{s \\mu \\sigma}}\n\\] From Abramowitz & Stegun (1972) we obtain \\[\ng(r, t) = \\frac{(\\mu \\sigma)^{1/2}}{(2 \\pi t)^{3/2}}\ne^{- \\frac{\\mu\\sigma r^2}{4 t}} \\, u(t)\n\\]\n\\(u(t)\\) is the Heaviside step function\n\\[\n    u(t) = \\begin{cases} 0 & t &lt; 0 \\\\ 1 & t &gt; 0. \\end{cases}\n\\]\n\n\n7.6.3 Numerical experiments with the time-domain Green’s function\nWe implement the Green’s function in Python and plot it as a function of time or source-receiver-offset, resp.\nAt first, let’s calculate the Green’s function at a fixed distance of \\(r=100\\) m for a time range of \\(t \\in [10^{-6}, 10^{-2}]\\) seconds.\nThe late time asymptotic \\(g(r,t) \\sim t^{-3/2}\\) as \\(t \\to \\infty\\) is indicated as a straight line in the log-log plot.\n\n\nShow the code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef green(sigma, r, t):\n    mu = np.pi * 4e-7\n    g = np.sqrt(mu * sigma) / (2 * np.pi * t)**1.5 * \\\n        np.exp(-0.25 * mu * sigma * r**2 / t)\n    return g\n\nsigma = 0.01\nr = np.logspace(start=0, stop=4, num=41, endpoint=True)\nt = np.logspace(start=-6, stop=-2, num=41, endpoint=True)\n\nrfix = 100\ntfix = 1e-6\ng_t = [green(sigma, rfix, tt) for tt in t]\ng_r = [green(sigma, rr, tfix) for rr in r]\n\nfig, ax = plt.subplots(1, 1, figsize=(4,4), layout='constrained')\nax.loglog(t, g_t, label=r'$g(r,t)$')\nax.loglog(t, 1e-6 * t**(-1.5), label=r'$t^{-3/2}$')\nax.set_ylim((1e-4, 1e2))\nax.set_xlabel('t in s')\nax.set_ylabel(r'$g(r,t)$')\nax.set_title(\"r = \" + str(rfix) + \" m\")\nax.grid(True)\nax.legend()\n\n\n\n\n\n\n\n\n\nThe following animation shows the interplay between the spatial decay of the Green’s function with time on the left, and the evolution of the Green’s function evaluated at a fixed point in space on the left.\nNote the red dots and the red horizontal lines which links both subfigures to each other.",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "potentials.html#the-fields-of-a-dipole-source-in-full-space",
    "href": "potentials.html#the-fields-of-a-dipole-source-in-full-space",
    "title": "7  Sources in unbounded media",
    "section": "7.7 The fields of a dipole source in full-space",
    "text": "7.7 The fields of a dipole source in full-space\nIf we compare 7.5 and 7.2, we recognize the similarity of both PDEs. More specifically, if we would be able to orientate \\(\\mathbf J\\) in such a way that it would be aligned to one of the Cartesian axis, then \\[\n\\mathbf J_m^s(\\mathbf r) = i \\omega \\mu \\mathbf m \\delta^3(\\mathbf r)\n\\] would simplify for a vertically aligned dipole to \\[\n\\mathbf J_m^s(\\mathbf r) = i \\omega \\mu \\begin{bmatrix}\n0 \\\\ 0 \\\\ m\n\\end{bmatrix} \\delta^3(\\mathbf r) =\n\\begin{bmatrix}\n0 \\\\ 0 \\\\ J_m^s\n\\end{bmatrix}\n\\] The vector-valued PDE 7.2 would turn into \\[\n\\nabla^2 \\mathbf F + k^2 \\mathbf F = -i \\omega \\mu m \\delta^3(\\mathbf r) \\mathbf e_z,\n\\] hence, the scalar potential for a magnetic dipole aligned with the \\(z\\)-axis is \\[\nF_z = \\mathbf F \\cdot \\mathbf e_z = \\frac{ i \\omega \\mu m }{ 4 \\pi r } e^{-i k r}.\n\\]\n\n\n\n\n\n\nTip\n\n\n\nThe potential of a dipole embedded in a uniform fullspace can be calculated with the help of the Green’s function.\nDipole induction problems become particularly easy to solve when the dipole axis is aligned with a Cartesian axis.\n\n\nWith the ansatz defined above \\[\n\\mathbf E_m = - \\nabla \\times \\mathbf F\n\\] and \\[\n\\mathbf H_m = \\frac{ 1 }{ i \\omega \\mu } (\\nabla \\nabla \\cdot \\mathbf F + k^2 \\mathbf F)\n\\] we can calculate the components of the electric and magnetic fields in a straightforward manner.\nNote that there are just spatial derivatives involved.\nHowever, the symmetry of the problem suggests using cylindrical coordinates.\n\\[\n\\begin{align}\n    \\nabla \\times \\mathbf F = & \\left(\n        \\frac{1}{r}\n    \\frac{\\partial F_z}{\\partial \\varphi}-\n    \\frac{\\partial F_\\varphi}{\\partial z}\n    \\right){\\mathbf e_r} + \\\\\n    & \\left(\\frac{\\partial F_r}{\\partial z}-\n    \\frac{\\partial F_z}{\\partial r}\n    \\right) {\\mathbf e_\\varphi} + \\\\\n    & \\frac{1}{r} \\left(\n        \\frac{\\partial \\left(r F_\\varphi\\right)}{\\partial r}-\n    \\frac{\\partial F_r}{\\partial \\varphi}\n    \\right){\\mathbf e_z}.\n\\end{align}\n\\tag{7.6}\\]\nIn the case of a dipole oriented in \\(z\\)-direction, the curl simplifies to \\[\n\\nabla \\times \\mathbf F = - \\frac{\\partial F_z}{\\partial r} \\mathbf e_\\varphi,\n\\tag{7.7}\\] where \\(\\mathbf e_\\varphi\\) is the unit coordinate vector in \\(\\varphi\\)-direction.\n\n\n\n\n\n\nNote\n\n\n\nSince the dipole axis is aligned with the \\(z\\)-axis, we expect axisymmetric field components.\nThe magnetic field forms closed field lines which are uniform in the azimuthal \\(\\varphi\\)-direction.\nFor a magnetic dipole aligned with the \\(z\\)-direction we observe the field components \\[\nE_\\varphi,\\quad H_r,\\quad H_z.\n\\]\nThe components are mutual orthogonal!\n\n\n\n7.7.1 Electric field\nWith the definition \\[\n\\mathbf E = -\\nabla \\times \\mathbf F\n\\] we find using 7.7 that \\[\nE_\\varphi = \\frac{\\partial F_z}{\\partial r}.\n\\] Hence, \\[\nE_\\varphi = \\partial_r F_z = -\\frac{i \\omega \\mu m }{4 \\pi r^2} (1 + i k r) \\exp(-i k r).\n\\]\n\n\n\n\n\n\nSelf study\n\n\n\nDo the derivation by yourself.\n\n\nThe change of the basis from cylindrical to Cartesian coordinates requires for the horizontal components \\[\n\\mathbf E = E_\\varphi \\mathbf e_\\varphi = E_\\varphi\n\\begin{pmatrix}\n-\\sin\\varphi \\\\\n\\cos\\varphi\n\\end{pmatrix},\n\\]\nsince\n\\[\n\\begin{bmatrix}\n\\mathbf e_r \\\\ \\mathbf e_\\varphi \\\\ \\mathbf e_z\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\cos\\varphi & \\sin\\varphi & 0 \\\\\n-\\sin\\varphi & \\cos\\varphi & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf e_x \\\\ \\mathbf e_y \\\\ \\mathbf e_z\n\\end{bmatrix}.\n\\]\nWith the angle \\(\\varphi\\) counting positive from the \\(x\\)-axis in the direction of \\(y\\), we can use the relations\n\\[\n\\cos\\varphi = \\frac{x}{r}, \\quad \\sin\\varphi = \\frac{y}{r}.\n\\]\nHence, \\[\n\\begin{align}\nE_x & = +i \\omega \\mu m \\frac{\\sin\\varphi}{4 \\pi r^2}(1 + i k r) \\exp(-i k r) \\\\\nE_y & = -i \\omega \\mu m \\frac{\\cos\\varphi}{4 \\pi r^2}(1 + i k r) \\exp(-i k r)\n\\end{align}\n\\]\nA useful expression for an arbitrary orientation of the dipole is given by\n\\[\n\\mathbf E(\\mathbf r) = -\\frac{i \\omega \\mu}{4 \\pi r^3} (1 + i k r) \\exp(-i k r) \\mathbf m \\times \\mathbf r,\n\\]\nwhere the components of \\(\\mathbf E\\) depend on both the direction of the dipole moment and the direction to the source.\nCheck:\nWith \\[\n\\mathbf m =\n\\begin{bmatrix}\n0 \\\\ 0 \\\\ m\n\\end{bmatrix}\n\\] and \\[\n\\mathbf r =\n\\begin{bmatrix}\nx \\\\ y \\\\ z\n\\end{bmatrix}\n\\] we obtain \\[\n- \\mathbf m \\times \\mathbf r =\n\\begin{bmatrix}\nmy \\\\ -mx \\\\ 0\n\\end{bmatrix} =\n\\begin{bmatrix}\nm r \\sin\\varphi \\\\ -m r \\cos\\varphi \\\\ 0\n\\end{bmatrix}\n.\n\\]\n\n\n\n\n\n\nNote\n\n\n\nLooking in the direction of the positive \\(z\\)-axis of a right-handed coordinate system, the induced electric field is oriented counter-clockwise, when \\(\\mathbf m\\) is oriented in positive \\(z\\)-direction.\n\n\n\n\n7.7.2 Magnetic field\nFor the magnetic field, we need \\[\n\\mathbf H = -\\sigma \\mathbf F + \\frac{1}{i\\omega\\mu} \\nabla\\nabla\\cdot\\mathbf F = \\frac{1}{i\\omega\\mu} \\left(\n    k^2 \\mathbf F + \\nabla\\nabla\\cdot\\mathbf F\n\\right).\n\\]\nThe \\(\\nabla\\cdot\\)-operator requires the calculation of \\(\\partial_z F_z\\), whereas the gradient requires to provide all partial derivatives of \\(\\partial_z F_z\\) with respect to \\(r\\) and \\(z\\).\nWe recall that \\[\nr = \\sqrt{x^2 + y^2 + z^2}\n\\] and use the chain rule to obtain \\[\n\\partial_z F_z = \\partial_r F_z \\cdot \\partial_z r,\n\\] where \\[\n\\partial_z r = \\frac{ z }{ r}.\n\\]\nFurther, the divergence and gradient operators generally read in cylindrical coordinates for a vector field \\(\\mathbf F\\) and a scalar field \\(f\\) \\[\n\\nabla \\cdot \\mathbf F = \\frac{1}{r} \\partial_r(r F_r) +\n\\frac{1}{r} \\partial_\\varphi F_\\varphi +\n\\partial_z F_z\n\\] and \\[\n\\nabla f = \\partial_r f \\mathbf e_r +\n\\frac{1}{r} \\partial_\\varphi f \\mathbf e_\\varphi +\n\\partial_z f \\mathbf e_z.\n\\]\nIn our case we need to calculate \\[\n\\nabla \\cdot \\mathbf F = \\partial_z F_z.\n\\]\nTo compute the derivatives, we use sympy:\n\n\nShow the code\nfrom sympy import diff, symbols, sqrt, pi, exp, I, simplify, Derivative, Matrix\nx, y, z, r, omega, mu, sigma, m = symbols('x y z r omega mu_0 sigma m', real=True)\nk = symbols('k')\n\nFz = I * omega * mu * m / (4 * pi * r) * exp(-I * k * r)\nprint('Fz = ')\nFz\n\n\nFz = \n\n\n\\(\\displaystyle \\frac{i m \\mu_{0} \\omega e^{- i k r}}{4 \\pi r}\\)\n\n\nNext, we implement an expression for \\(\\nabla \\cdot \\mathbf F\\):\n\n\nShow the code\ndivF = diff(Fz.subs(r, sqrt(x**2 + y**2 + z**2)), z).subs(sqrt(x**2 + y**2 + z**2), r).simplify()\nprint('divF = ')\ndivF\n\n\ndivF = \n\n\n\\(\\displaystyle \\frac{m \\mu_{0} \\omega z \\left(k r - i\\right) e^{- i k r}}{4 \\pi r^{3}}\\)\n\n\nThe chain rule can be implemented by a lambda function chain which first substitutes \\(r\\) by the square root, forms the derivative, and finally substitutes all square root expressions by \\(r\\) or powers thereof.\n\n\nShow the code\nchain = lambda F, v: diff(F.subs(r, sqrt(x**2 + y**2 + z**2)), v).subs(sqrt(x**2 + y**2 + z**2), r).simplify()\n\n\nA call to chain, i.e., the implementation of \\(\\partial_z \\partial_z F_z\\) would simply look as follows:\nchain(Fz, z)\nHowever, to get the magentic field components, we need to divide by the term \\(i \\omega \\mu_0\\).\n\n\nShow the code\nHx = chain(divF, x).factor() / (I * omega * mu)\nprint('Hx =')\nHx\n\n\nHx =\n\n\n\\(\\displaystyle - \\frac{m x z \\left(k^{2} r^{2} - 3 i k r - 3\\right) e^{- i k r}}{4 \\pi r^{5}}\\)\n\n\n\n\nShow the code\nHy = chain(divF, y).factor() / (I * omega * mu)\nprint('Hy =')\nHy\n\n\nHy =\n\n\n\\(\\displaystyle - \\frac{m y z \\left(k^{2} r^{2} - 3 i k r - 3\\right) e^{- i k r}}{4 \\pi r^{5}}\\)\n\n\nTo get \\(H_z\\) we have to add the term \\(k^2 F_z\\) as\n\n\nShow the code\nHz = (chain(divF, z) + k**2 * Fz) / (I * omega * mu)\nprint('Hz =')\nHz.factor().simplify()\n\n\nHz =\n\n\n\\(\\displaystyle \\frac{m \\left(k^{2} r^{4} - k^{2} r^{2} z^{2} - i k r^{3} + 3 i k r z^{2} - r^{2} + 3 z^{2}\\right) e^{- i k r}}{4 \\pi r^{5}}\\)\n\n\nWe can generalize using the following notation: \\[\n\\mathbf H(\\mathbf r) = \\frac{1}{4 \\pi r^3} \\left[\n    \\frac{\\mathbf m \\cdot \\mathbf r}{r^2} (3 + 3 i k r - k^2 r^2) \\mathbf r - (1 + i k r - k^2 r^2) \\mathbf m\n    \\right] e^{-i k r}.\n\\]\nLet’s check the validity on our example.\nWe introduce the symbolic vector quantities M and R, and implement a lambda function to express the magnetic field with respect to the orientation of the magnetic dipole moment:\n\n\nShow the code\nM = Matrix([0, 0, m])\nR = Matrix([x, y, z])\nH = lambda M: (M.dot(R) * (3 + I * k * r - k**2 * r**2) * R / r**2 - (1 + I * k * r - k**2 * r**2) * M) * exp(-I * k * r) / (4 * pi * r**3)\nprint('H(M) =')\nH(M)\n\n\nH(M) =\n\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{m x z \\left(- k^{2} r^{2} + i k r + 3\\right) e^{- i k r}}{4 \\pi r^{5}}\\\\\\frac{m y z \\left(- k^{2} r^{2} + i k r + 3\\right) e^{- i k r}}{4 \\pi r^{5}}\\\\\\frac{\\left(- m \\left(- k^{2} r^{2} + i k r + 1\\right) + \\frac{m z^{2} \\left(- k^{2} r^{2} + i k r + 3\\right)}{r^{2}}\\right) e^{- i k r}}{4 \\pi r^{3}}\\end{matrix}\\right]\\)\n\n\nThis confirms the correctness of our derivation.",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "potentials.html#apparent-resistivity",
    "href": "potentials.html#apparent-resistivity",
    "title": "7  Sources in unbounded media",
    "section": "7.8 Apparent resistivity",
    "text": "7.8 Apparent resistivity\nHowever, geophysics is primarily interested in reconstructing the spatial distribution of electrical conductivity from measured field quantities (inversion). This step is based on a model conception of the spatial conductivity distribution. In general, the conductivity is a function of location with \\(\\sigma=\\sigma(x,y,z)&gt;0\\). In the simplest case, we assume that the halfspace or fullspace is a uniform conductor, i.e., \\(\\sigma= const\\). The model of the homogeneous halfspace or fullspace can therefore be completely described by a single number. We now try to determine this number mathematically from the measured field quantities.\nThis is the simplest form of a geophysical inversion!\nWe use the impedance to solve the problem. From this we then determine the apparent resistivity.\nThe following questions will be answered:\n\nCan the concept of impedance be transferred to dipole excitation?\nIs it possible to reconstruct the electrical resistivity from the impedance?\nWhat are the differences compared to homogeneous excitation (MT)?\n\nWe implement the general equations for the electric and magnetic fields as Python functions E and H, resp.:\n\n\nShow the code\ndef E(r, m, f, sigma):\n    mu = np.pi * 4e-7\n    omega = 2 * np.pi * f\n    iwm = 1j * omega * mu\n    alpha = iwm / (4 * np.pi)\n    k = np.sqrt(-iwm * sigma)\n    x = r[0]\n    y = r[1]\n    z = r[2]\n    R = np.linalg.norm(r)\n    ikr = 1j * k * R\n    E = -alpha / R**3 * (1.0 + ikr) * np.exp(-ikr) * np.cross(m, r)\n    return E\n\ndef H(r, m, f, sigma):\n    mu = np.pi * 4e-7\n    omega = 2 * np.pi * f\n    iwm = 1j * omega * mu\n    k = np.sqrt(-iwm * sigma)\n    x = r[0]\n    y = r[1]\n    z = r[2]\n    R = np.linalg.norm(r)\n    ikr = 1j * k * R\n    k2r2 = k**2 * R**2\n    H = np.exp(-ikr) / (4 * np.pi * R**3) * (\n        \n            np.dot(m, r) / R**2 * (3 + 3 * ikr - k2r2) * r\n            -\n            (1 + ikr - k2r2) * m\n        )\n    return H\n\n\nWe check with the following parameters:\n\n\\(\\mathbf r = [100, 0, 0]^\\top\\) m\n\\(\\mathbf m = [0, 0, 1]^\\top\\) A\\(\\cdot m^2\\)\n\\(f = 100\\) Hz\n\\(\\sigma = 0.01\\) S/m.\n\n\n\nShow the code\nr = np.array([100.0, 0.0, 0.0])\nm = np.array([0.0, 0.0, 1.0])\nf = 100.0\nsigma = 0.01\ne = E(r, m, f, sigma)\nEy = e[1]\ne\n\n\narray([ 0.00000000e+00-0.00000000e+00j, -2.15431872e-10-6.25496586e-09j,\n        0.00000000e+00-0.00000000e+00j])\n\n\n\n\nShow the code\nh = H(r, m, f, sigma)\nHz = h[2]\nh\n\n\narray([ 0.00000000e+00+0.00000000e+00j,  0.00000000e+00+0.00000000e+00j,\n       -8.02368029e-08-2.32115274e-09j])\n\n\nWe recognize that for a vertically aligned dipole, when observed at the \\(x\\)-axis, only the \\(y\\)-component of \\(\\mathbf E\\) and the \\(z\\)-component of \\(\\mathbf H\\) are non-zero.\nNow we try to calculate the impedance from the ratio of two mutually orthogonal components of \\(\\mathbf E\\) and \\(\\mathbf H\\), e.g., \\[\nZ = \\frac{ E_y }{ H_z}.\n\\]\n\n\nShow the code\nZ = Ey / Hz\nZ\n\n\n(0.004936001185549236+0.07781352726165937j)\n\n\nFor the calculation of the apparent resistivity, we use \\[\n\\rho_a = \\frac{ 1 }{ \\omega \\mu_0} |Z|^2\n\\]\n\n\nShow the code\ndef rhoa(Z, f):\n    mu = np.pi * 4e-7\n    omega = 2 * np.pi * f\n    return np.abs(Z)**2 / (omega * mu)\n\n\n\n\nShow the code\nrhoa(Z, f)\n\n\n7.699534963039838\n\n\nThis does not meet our expectations. We are therefore investigating whether the impedance depends on the frequency and/or the distance to the dipole.\nWe vary the frequencies and observe \\(\\rho_a\\) as a function of frequency.\n\n\nShow the code\nnf = 41\nfreq = np.logspace(1, 5, nf, endpoint=True)\nRhoa_f = [rhoa(E(r,m,v,sigma)[1] / H(r,m,v,sigma)[2], v) for v in freq]\n\n\n\n\nShow the code\nimport matplotlib.pyplot as plt\n\nplt.loglog(freq, Rhoa_f)\nplt.grid(True)\nplt.xlabel('f in Hz')\nplt.ylabel(r'$\\rho_a~in~\\Omega\\cdot m$')\nplt.title('Dipole offset ' + str(np.linalg.norm(r)) + ' m')\nplt.show()\n\n\n\n\n\n\n\n\n\nObviously, the value of \\(\\rho_a\\) depends on the frequency and asymptotically approaches the expected full-space value of the resistivity as \\(f \\to \\infty\\).\nWe gain more insight, when we vary the distance to the dipole while keeping the frequency fixed.\n\n\nShow the code\nnr = 41\nx = np.logspace(0, 4, nr, endpoint=True)\nRhoa_x = np.array([rhoa(E(np.array([v, 0, 0]),m,f,sigma)[1] / H(np.array([v, 0, 0]),m,f,sigma)[2], f) for v in x])\n\n\n\n\nShow the code\nplt.loglog(x, Rhoa_x)\nplt.grid(True)\nplt.xlabel('r in m')\nplt.ylabel(r'$\\rho_a~in~\\Omega\\cdot m$')\nplt.title('Frequency ' + str(np.linalg.norm(f)) + ' Hz')\nplt.show()\n\n\n\n\n\n\n\n\n\nIs there a consistent explanation for these observations? We look at the induction parameter \\(|k|r\\) and revisit the parameters from the previous examples.\n\n\nShow the code\ndef kr(f, sigma, r):\n    mu = np.pi * 4e-7\n    omega = 2 * np.pi * f\n    return r * np.abs(np.sqrt(-1j * omega * mu * sigma))\n\ndef pos(data, threshold):\n    return np.where(np.array(data) &gt; threshold, data, np.nan)\n\n\n\n\nShow the code\nKR = np.array([kr(v, sigma, np.linalg.norm(r)) for v in freq])\nplt.loglog(freq, KR, color='C1', label=r'|k|r &gt; 1')\niind = np.argwhere(KR &lt; 1)\nplt.loglog(freq[iind], KR[iind], color='C0', label=r'|k|r &lt; 1')\nplt.legend()\nplt.grid(True)\nplt.ylabel(r'$|k|r$')\nplt.xlabel('f in Hz')\nplt.title('Dipole offset ' + str(np.linalg.norm(r)) + ' m')\nplt.show()\n\n\n\n\n\n\n\n\n\nWith the indicator \\(|k|r\\) just introduced, it is easier to determine which branch of the asymptotic we are on.\n\n\nShow the code\nKR = np.array([kr(f, sigma, v) for v in x])\nplt.loglog(x, Rhoa_x, color='C1', label=r'$|k|r &gt; 1$')\niind = np.argwhere(KR &lt; 1)\nplt.loglog(x[iind], Rhoa_x[iind], color='C0', label=r'$|k|r &lt; 1$')\nplt.legend()\nplt.grid(True)\nplt.xlabel('r in m')\nplt.ylabel(r'$\\rho_a~in~\\Omega\\cdot m$')\nplt.title('Frequency ' + str(np.linalg.norm(f)) + ' Hz')\nplt.show()\n\n\n\n\n\n\n\n\n\nIn contrast to homogeneous excitation, the impedance and thus the apparent resistivity for dipole excitation depends not only on the frequency but also on the distance between the dipole source and the receiver. At \\(|k|r \\gg 1\\) we speak of the far zone. The impedance relationships there are similar to those for the MT. At \\(|k|r \\ll 1\\) we are in the near zone. The induction parameter is small. The low induction number (LIN) methods work in this regime. With the Geonics EM-34, for example, a coil distance of around 10 m is selected at a frequency of 6,400 Hz. The induction parameter for this configuration is less than 1 if the conductivity is sufficiently low.\nWe check these findings for a range of conductivities.\n\n\nShow the code\nns = 41\nsigma = np.logspace(-4, 0, ns, endpoint=True)\nr = 10.0\nf = 6400.0\nKR = np.array([kr(f, v, r) for v in sigma])\n\nHz = np.array([H(np.array([r, 0, 0]), np.array([0, 0, 1]), f, v)[2] for v in sigma])\n\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n\nax1.loglog(KR, np.abs(np.real(Hz)))\nax1.axvspan(KR[0], 1.0, facecolor='lightgreen', alpha=0.4)\nax1.axvspan(1.0, KR[-1], facecolor='red', alpha=0.4)\nax1.grid(True)\nax1.set_ylabel(r'$|Re(H_z)|$')\nax2.loglog(KR, np.abs(np.imag(Hz)))\nax2.axvspan(KR[0], 1.0, facecolor='lightgreen', alpha=0.4)\nax2.axvspan(1.0, KR[-1], facecolor='red', alpha=0.4)\nax2.grid(True)\nax2.set_xlabel(r'$|k|r$')\nax2.set_ylabel(r'$|Im(H_z)|$')\nplt.show()\n\n\n\n\n\n\n\n\nFigure 7.1: Real and imaginary part of the magnetic field of an oscillating magnetic dipole. The green and red shading indicates the regime for \\(|k|r &lt; 1\\) and \\(|k|r &gt; 1\\), resp.\n\n\n\n\n\nAs we can see from Fig. Figure 7.1, the real part of the magnetic field goes to a constant value for \\(|k|r \\to 0\\), whereas the imaginary part shows a straight line in the log-log plot.\nFor \\(|k|r \\to 0\\), i.e., for very small conductivities, we approach free-space conditions. The magnetic field of a vertical dipole in horizontal co-planar configuration is \\[\nH_z = -\\frac{ m }{4 \\pi r^3 }.\n\\]\nWe evaluate this equation with the given values of \\(r\\) and \\(m\\). We obtain\n\n\nShow the code\nprint('H_z   = ' + str(-1 / (4 * np.pi * r**3)))\nprint('Hz[0] = ' + str(np.real(Hz[0])))\n\n\nH_z   = -7.957747154594768e-05\nHz[0] = -7.957789009530794e-05\n\n\nThese numbers match very well.\nOn the other hand, for fixed values of \\(r\\) and \\(f\\) it is possible to calibrate the instrument such that the reading of the imaginary part of \\(H_z\\) for low induction numbers yields the desired apparent resistivity.\n\n7.8.1 Instrument error\nWhat about the uncertainty of the readings of such an instrument?\nFrequency stability in the instrument is not a problem. The situation is different when measuring the distance between the coils. We therefore finally examine the sensitivity of the magnetic field measurement to inaccuracies in the distance measurement. To do this, we consider the error according to the linear error propagation law\n\\[\n\\Delta H_z = \\left| \\frac{\\partial H_z}{\\partial r} \\right| \\Delta r.\n\\]\nFor the magnetic field in the coplanar coil configuration in free space, we obtain \\[\n\\Delta H_z = \\frac{3 m}{4 \\pi r^4} \\Delta r,\n\\]\nwhich results in an estimate of the relative error\n\\[\n\\frac{\\Delta H_z}{H_z} = 3 \\frac{\\Delta r}{r} .\n\\]\nAccordingly, the relative error in the magnetic field measurement is three times as large as the relative error in the distance measurement.\n\n\n\n\nAbramowitz, M. & Stegun, I.A., 1972. Handbook of mathematical functions with formulas, graphs, and mathematical tables, Tenth., Dover Publications.",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Sources in unbounded media</span>"
    ]
  },
  {
    "objectID": "timedomain_fullspace.html",
    "href": "timedomain_fullspace.html",
    "title": "8  Fields in the time domain",
    "section": "",
    "text": "8.1 Introduction\nSo far, we have investigated fields as a function of location and frequency. This is adequate as long as we consider time-harmonic dipole excitation with a time dependency of the dipole moment of \\(e^{i\\omega t}\\), i.e.\n\\[\n\\mathbf m(\\mathbf r, \\omega) = \\mathbf m(\\mathbf r) e^{i\\omega t}.\n\\]\nThe relationships immediately become different if we allow abrupt changes in the dipole moment instead, e.g.,\n\\[\n\\mathbf m(\\mathbf r, t) = \\mathbf m(\\mathbf r) \\delta(t)\n\\] or \\[\n\\mathbf m(\\mathbf r, t) = \\mathbf m(\\mathbf r) u(t).\n\\]\n\\(u(t)\\) is the Heaviside step function \\[\n\\begin{equation}\nu(t) =\n\\begin{cases}\n0 & t &lt; 0 \\\\\n1 & t &gt; 0.\n\\end{cases}\n\\end{equation}\n\\]\nThe following figures show the Heaviside function \\(u(t)\\) and the result of the time integration of the Dirac delta function \\(\\delta(t)\\).\nWe use the symbolic expressions t for the time as well as Heaviside and DiracDelta for step function and Dirac’s delta function respectively. Furthermore, we use the function integrate for symbolic integration.\nShow the code\nimport numpy as np\nfrom sympy import symbols, diff, Heaviside, DiracDelta, integrate, plot, sqrt, exp, oo, erf, erfc, pi\nt = symbols('t', real=True)\nplot(Heaviside(t), (t, -1, 1), size=(6,3), title='Heaviside')\nThe following figure shows the result of the time integration of the Dirac delta function, where the integral over \\(\\delta(t)\\) from \\(-\\infty\\) to \\(t\\) is assigned to the value of a function at time \\(t\\).\nShow the code\nplot(integrate(DiracDelta(t), t), (t, -1, 1), size=(6,3), title=r'$\\int_{-\\infty}^t\\delta(\\tau) d\\tau$')\nBoth figures obviously show the same result. So the following applies \\[\nu(t) = \\int\\limits_{-\\infty}^t \\delta(\\tau) \\, \\mathrm d \\tau.\n\\]\nWe can reproduce the result using symbolic mathematics.\n(In sympy the Heaviside function has the symbol \\(\\theta\\)).\nintegrate(DiracDelta(t), t)\n\n\\(\\displaystyle \\theta\\left(t\\right)\\)\nConversely, the following applies to the time derivative of the Heaviside function \\[\n\\frac{\\mathrm d}{\\mathrm dt} u(t) = \\delta(t),\n\\] of which we can convince ourselves by symbolic differentiation:\ndiff(Heaviside(t), t)\n\n\\(\\displaystyle \\delta\\left(t\\right)\\)",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Fields in the time domain</span>"
    ]
  },
  {
    "objectID": "timedomain_fullspace.html#terminology",
    "href": "timedomain_fullspace.html#terminology",
    "title": "8  Fields in the time domain",
    "section": "8.2 Terminology",
    "text": "8.2 Terminology\nWe will use two important terms in the time domain, namely\n\nstep function response and\nimpulse response.\n\nThese terms are related to the time dependence of the current function of the dipole moment.\nIn general, the dipole moment is a function of location and time, i.e., \\(\\mathbf m(\\mathbf r, t) = \\mathbf q(\\mathbf r) I(t)\\). Here, \\(\\mathbf q(\\mathbf r)\\) describes the exact position of the current-carrying cable (e.g., a large horizontal coil on the Earth’s surface) and \\(I(t)\\) the time dependence of the current in this coil.\nIn the following, we only consider the time dependence of the dipole moment, i.e., \\(I(t)\\).\n\n8.2.1 Step function response\nThe fields that we can measure anywhere in the full space as a direct result of switching the source current on or off are called the step function response of the electrically conductive full space\nA current function of the form\n\\[\nI(t) = I_0 u(t)\n\\]\ndescribes the switching on of a current in the source at the time \\(t=0\\) in the form of a step function. The fields \\(\\mathbf e(t)\\) and \\(\\mathbf b(t)\\) observed for \\(t &gt; 0\\) are called step function response. These fields are measured with electrodes or magnetometers.\n\n\n8.2.2 Impulse response\nThe current function\n\\[\nI(t) = I_0 \\delta(t)\n\\]\ndescribes an impulse-like source current (“lightning”), which, however, cannot be realized in an instrument and is difficult to measure.\nHow can we measure the impulse response?\nThe following idea is interesting: If you measure magnetic fields with induction coils, the physical measured variable is the electrical voltage induced in the measuring coil, which is proportional to the change in the magnetic field over time.\nInduction coils measure \\(\\partial_t b(t)\\), i.e. the time derivative of the step function response \\(b(t)\\)!\nHow can this relationship be described?\nWe have already seen above that the integration of the Dirac delta function with respect to time yields the Heaviside jump function. Conversely, the time derivative of the step function yields the delta function, i.e. a Dirac impulse.\nWe transfer this concept to the fields:\n\n\n\nfield size\ntime dependence of the source\nterm\n\n\n\n\n\\(\\mathbf e(t),\\mathbf b(t)\\)\n\\(u(t)\\)\nStep function response\n\n\n\\(\\frac{d}{dt} \\mathbf b(t)\\)\n\\(\\frac{d}{dt} u(t)\\)\nimpulse response\n\n\n\\(\\frac{d}{dt} \\mathbf b(t)\\)\n\\(\\delta(t)\\)\nimpulse response\n\n\n\n\n\n8.2.3 Differentiation, integration, convolution\nWe now derive an important relationship between the impulse response and the step function response.\nLet \\(h(t)\\) be the impulse response.\n\n\n\n\n\n\nNote\n\n\n\nThe impulse response \\(h(t)\\) used here a physically unspecified function of time, not the magnetic field!\n\n\nWe then obtain the step function response \\(f(t)\\) from the convolution of the impulse response \\(h(t)\\) with the Heaviside function \\(u(t)\\):\n\\[\nf(t)=h * u(t)=u * h(t)=\\int_{-\\infty}^{\\infty} h(t') u(t-t') d t' =\\int_{-\\infty}^{t} h(t') d t'\n\\]\nThe step function response at time \\(t\\) is therefore the result of the time integration over the impulse response from \\(-\\infty\\) to \\(t\\).\nIn the following example, we assume that the impulse response is \\(h(t) = e^{-t^2}\\).\n\n\nShow the code\ndef h(t):\n     return exp(-t**2)\nplot(h(t), (t, -10, 10), size=(6,3), ylabel='h(t)')\n\n\n\n\n\n\n\n\n\nWe define symbolic expressions for the integrals introduced above to calculate \\(f(t)\\):\n\\[\nf_1(\\tau) = \\int_{-\\infty}^{\\infty} h(t) u(\\tau-t) \\mathrm d t\n\\] \\[\nf_2(\\tau) = \\int_{-\\infty}^{\\tau} h(t') d t'\n\\]\n\ntau = symbols('tau', real=True)\ndef f1(tau):\n    return integrate(h(t) * Heaviside(tau - t), (t, -oo, oo))\n\ndef f2(tau):\n    return integrate(h(t), (t, -oo, tau))\n\n\nf1(tau)\n\n\\(\\displaystyle \\frac{\\sqrt{\\pi} \\left(2 - \\operatorname{erfc}{\\left(\\tau \\right)}\\right)}{2}\\)\n\n\n\nf2(tau)\n\n\\(\\displaystyle \\frac{\\sqrt{\\pi} \\left(2 - \\operatorname{erfc}{\\left(\\tau \\right)}\\right)}{2}\\)\n\n\nWe see that both integrals yield the same result, so \\(f(t) = f_1(t) = f_2(t)\\). For further calculations, it is sufficient to use the integral\n\\[\nf(t) = \\int_{-\\infty}^t h(t') \\, \\mathrm dt'.\n\\]\n\n\n\n\n\n\nNote\n\n\n\nBoth integrals involve the complementary error function erfc, which will be discussed later in more detail.\n\n\n\n\n8.2.4 Causal systems\nOnly causal systems occur in geophysics. In causal processes, no fields (or changes in the fields) can be measured before the source has been switched on (or changed). The effect is observed as a consequence of one of the causes.\nThe step function response for causal systems is\n\\[\nf_{\\mathrm{on}}(t)=\\int_{0}^{t} h(t') \\, \\mathrm d t', \\quad t \\geq 0.\n\\]\n\n\nShow the code\ndef f_on(tau):\n    return integrate(h(t), (t, 0, tau))\n\nplot(f_on(t), (t, 0, 10), ylim=(0, 1), size=(6,3), title=r'$f_\\text{on}(t)$')\n\n\n\n\n\n\n\n\n\nWith \\(u(-t) = 1 - u(t)\\) we obtain the step function response for the switch-off process, which plays a major role in transient electromagnetics in particular, but also in the induced polarization method in the time domain.\n\\[\nf_{\\text {off }}(t) =\\int_{t}^{\\infty} h(t') d t' = \\int_{0}^{\\infty} h(t') d t' - \\int_{0}^{t} h(t') d t', \\quad t \\geq 0\n\\]\nThe integrals can be expressed by the step function response for causal systems \\(f_{\\text {on }}(t)\\):\n\\[\nf_{\\text {off }}(t) = f_{\\text {on }}(\\infty) - f_{\\text {on }}(t), \\quad t \\geq 0\n\\]\nThis means that all we need to calculate the step function response of transient electromagnetics is a routine that can calculate the step response for the switch-on process!\n\n\nShow the code\ndef f_off(tau):\n    return f_on(oo) - f_on(tau)\n\nplot(f_off(t), (t, 0, 10), ylim=(0, 1), size=(6,3), title=r'$f_\\text{off}(t)$')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe figure for \\(f_\\text{on}(t)\\) shows the typical behaviour of a field build-up after the source is switched on. We observe an increase in the field and a transition to a stationary state for \\(t \\to \\infty\\).\n\\(f_\\text{off}(t)\\) shows the decay of the field, where the initial value at \\(t=0\\) decreases monotonically for \\(t &gt; 0\\) to disappear for \\(t \\to \\infty\\).\n\n\nWe will now deal with the transformation between the time and frequency domains. To do this, we need the Laplace transformation (LT) and its properties.\nThe starting point is the comparison of the curl-curl equation in the time domain and in the frequency domain.\nIn the frequency domain we require \\(F\\) to be a solution to the PDE\n\\[\n\\begin{equation}\n-\\partial_{xx}^2 F + i\\omega\\mu\\sigma F = -i\\omega J^{e}\n\\end{equation}\n\\] with \\[\n\\begin{equation}\nJ^e(\\mathbf r, \\omega) = q(\\mathbf r).\n\\end{equation}\n\\]\nIn the time domain, the field \\(f\\) solves the PDE\n\\[\n\\begin{equation}\n-\\partial_{xx}^2 f + \\mu\\sigma \\partial_{t} f = -\\partial_{t} j^{e}\n\\end{equation}\n\\] with \\[\n\\begin{equation}\nj^e(\\mathbf r, t) = q(\\mathbf r) \\delta(t).\n\\end{equation}\n\\]\nObservations:\nIn the frequency domain, there is no explicit dependence of the source current density \\(J^e(\\mathbf r, \\omega)\\) on the frequency.\nWe conclude from this that in the time domain, the source current function \\(j^e\\) can be explicitly represented by a Dirac impulse on the time axis. The solution of this curl-curl equation is the impulse response.\nThe solution of the curl-curl equation in the frequency domain is then obtained from the Fourier transform of the impulse response in the time domain.\nTo calculate the step function response in the frequency domain, we must calculate the explicit time dependence of \\(j^e\\) using the step function \\(u(t)\\)\n\\[\nj^e_s(t) = q(\\mathbf r) u(t).\n\\]\nWe obtain the Fourier transform of the source term with step function excitation:\n\\[\nJ^e_s(\\omega) = q(\\mathbf r) \\left(\\pi \\delta(\\omega) + \\frac{1}{i \\omega}\\right)\n\\]\nThe step function response in the frequency domain, \\(F_s(\\omega)\\), is thus obtained formally by multiplying the Fourier transform of the impulse response by the Fourier transform of the step function as \\[\nF_s(\\omega) = F(\\omega) \\left(\\pi \\delta(\\omega) + \\frac{1}{i \\omega}\\right) .\n\\]\nThe inverse Fourier transformation finally provides the desired step function response in the time domain,\n\\[\n\\begin{align}\nf_s(t) & = \\frac{1}{2\\pi} \\int\\limits_{-\\infty}^\\infty\n\\left(\\pi \\delta(\\omega) + \\frac{1}{i \\omega}\\right) F(\\omega) e^{i\\omega t} \\, \\mathrm d\\omega \\\\ & = \\frac{F(0)}{2} +\n\\frac{1}{2\\pi} \\int\\limits_{-\\infty}^\\infty\n\\frac{F(\\omega)}{i\\omega}\ne^{i\\omega t} \\, \\mathrm d\\omega\n\\end{align}\n\\]\nFormally, the Fourier transform must be added to half the value of the field at \\(\\omega = 0\\), where the values of \\(F\\) to be transformed are multiplied by \\(\\frac{1}{i\\omega}\\).\nThis corresponds to the known integration rule of integral transforms.\nMathematical problems in connection with switch-on or switch-off processes can be solved elegantly with the Laplace transform.\n\n\n8.2.5 Laplace transform\nConsider a function \\(f(t)\\), \\(t &gt; 0\\).\nThe Laplace transform can be applied to \\(f(t)\\) as follows: \\[\n\\mathcal L(f(x, t))=\\int_{0}^{\\infty} e^{-s t} f(x, t) d t \\equiv F(x, s)\n\\] with \\(x\\) as parameter.\nThe Laplace parameter \\(s\\) is complex and extends the imaginary frequency term \\(i\\omega\\) of the FT by the real part \\(a\\), so that with \\(s = a + i\\omega\\) we have a complex-valued “frequency”. In this way, the Laplace transform can also deal with unstable signals \\(f\\), since for \\(t \\to \\infty\\) the real part of \\(s\\) ensures that the integrand is limited.\nIn connection with PDEs, we also need the LT of the time derivative of \\(f(t)\\) (\\(f_t(x, t) = \\partial_t f(x, t)\\))\n\\[\n\\mathcal L(f_t(x, t)),\n\\]\nwhich we calculate using the Laplace integral introduced above via partial integration: \\[\n\\begin{align}\n\\mathcal L(f_t(x, t) & = \\int\\limits_{0}^{\\infty} e^{-s t} f_{t}(x, t) d t \\\\ & = \\left.e^{-s t} f(x, t)\\right|_{0} ^{\\infty}+s \\int\\limits_{0}^{\\infty} e^{-s t} f(x, t) d t \\\\ & = s F(x, s)-f(x, 0).\n\\end{align}\n\\]\nThe following table contains some important Laplace transform pairs:\n\n\n\n\\(f(t)\\)\n\\(\\mathcal L(f(t))\\)\n\n\n\n\n\\(u(t-a)\\)\n\\(\\frac{e^{-as}}{s}\\)\n\n\n\\(\\delta(t-a)\\)\n\\(e^{-as}\\)\n\n\n\\(1\\)\n\\(\\frac{1}{s}\\)",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Fields in the time domain</span>"
    ]
  },
  {
    "objectID": "timedomain_fullspace.html#inverse-transform-of-the-electric-field-with-step-function-excitation",
    "href": "timedomain_fullspace.html#inverse-transform-of-the-electric-field-with-step-function-excitation",
    "title": "8  Fields in the time domain",
    "section": "8.3 Inverse transform of the electric field with step function excitation",
    "text": "8.3 Inverse transform of the electric field with step function excitation\nThe starting point is the equation for the electric field of a magnetic dipole in full space.\nWith \\(r = |\\mathbf r|\\) it holds\n\\[\n    \\mathbf E(\\mathbf r, \\omega) = - \\frac{i \\omega \\mu}{4 \\pi r^3} \\left(1 + i k r\\right) e^{-i k r} \\mathbf m \\times \\mathbf r\n\\]\nAll terms that depend on the frequency are relevant for the transformation. Apart from the factor \\(i\\omega\\), which we will deal with later, these are\n\\[\ne^{-ikr}, \\quad ikr e^{-ikr}\n\\]\nand additionally\n\\[\n\\quad k^2 r^2 e^{-ikr}\n\\]\nfor the magnetic field.\nWith the function \\(\\Theta(t) = \\sqrt{\\frac{\\mu\\sigma}{4 t}}\\) we obtain the following expressions for the inverse Laplace transform (see Abramowitz & Stegun):\n\\[\n\\mathcal L^{-1} \\left( \\frac{1}{s} e^{-ikr} \\right) = \\mathrm{erfc}(\\Theta r)\n\\]\n\\[\n\\mathcal L^{-1} \\left( \\frac{ikr}{s} e^{-ikr} \\right) = \\frac{2}{\\sqrt{\\pi}} \\Theta r e^{-\\Theta^2 r^2}\n\\]\n\\[\n\\mathcal L^{-1} \\left( \\frac{k^2 r^2}{s} e^{-ikr} \\right) =\n-\\frac{4}{\\sqrt{\\pi}} \\Theta^3 r^3 e^{-\\Theta^2 r^2}\n\\]\n\n8.3.1 Error function\nThe error function erf\\((t)\\) plays an important role. Its definition is \\[\n\\mathrm{erf}(t) = \\frac{2}{\\sqrt{\\pi}} \\int_0^t e^{-\\tau^2} d\\tau.\n\\] The complementary error function erfc\\((t)\\) is \\[\n\\mathrm{erfc}(t) = 1 - \\mathrm{erf}(t).\n\\]\nWe implement the error function again with sympy.\n\n\nShow the code\nplot(erf(t), (t,0,2), size=(6,3), title='erf(t)')\nplot(erfc(t), (t,0,2), size=(6,3), title='erfc(t)')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.3.2 Summary of all terms\nAfter the LT we first have\n\\[\n\\mathbf e(\\mathbf r, t) = -\\partial_t \\frac{\\mu}{4 \\pi r^3} \\left(\n\\mathrm{erfc}(\\Theta r) + \\frac{2}{\\sqrt{\\pi}} \\Theta r e^{-\\Theta^2 r^2}\n\\right) \\mathbf m \\times \\mathbf r.\n\\]\nWe now carry out the derivative with respect to time. To do this, we need the chain rule again, since \\(\\Theta = \\Theta(t)\\).\n\n\nShow the code\nmu, sigma, r = symbols('mu_0 sigma r', real=True)\ndef Theta(t):\n    return sqrt(mu * sigma / 4 / t)\n\nex1 = diff(erfc(Theta(t) * r), t)\nex2 = diff(Theta(t) * r * exp(-Theta(t)**2 * r**2), t)\n\nex = ex1 + 2 / sqrt(pi) * ex2\n\nex.subs(sqrt(mu * sigma / 4 / t), Theta(t)).factor().simplify()\n\n\n\\(\\displaystyle \\frac{\\mu_{0} r^{3} \\sigma \\sqrt{\\frac{\\mu_{0} \\sigma}{t}} e^{- \\frac{\\mu_{0} r^{2} \\sigma}{4 t}}}{4 \\sqrt{\\pi} t^{2}}\\)\n\n\nWe slightly rewrite this term with the help of \\(\\Theta(t)\\) to get\n\\[\n\\frac{2}{\\sqrt{\\pi} t} \\Theta^3 r^3 e^{-\\Theta^2 r^2}.\n\\]\nWith the leading terms and the cross product we obtain the final result for the electric field as a step function response\n\\[\n\\mathbf e(\\mathbf r, t) = -\\frac{\\mu}{4 \\pi r^3}\n\\frac{2}{\\sqrt{\\pi} t} \\Theta^3 r^3 e^{-\\Theta^2 r^2}\n\\mathbf m \\times \\mathbf r.\n\\]\nWe implement this function using Python.\n\n\nShow the code\ndef Et(r, m, t, sigma):\n    mu = np.pi * 4e-7\n    R = np.linalg.norm(r)\n    theta = np.sqrt(mu * sigma / 4 / t)\n    tr = theta * R\n    t2r2 = tr**2\n    alpha = -mu / 4 / np.pi\n    E = alpha / R**3 * np.cross(m, r) * 2  / (\n        np.sqrt(np.pi) * t) * (tr * t2r2) * np.exp(-t2r2)\n    return E\n\n\n\n\nShow the code\nEt(np.array([0, 100, 0]), np.array([0, 0, 1]), 1e-6, 0.01)\n\n\narray([ 4.5124908e-17, -0.0000000e+00, -0.0000000e+00])",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Fields in the time domain</span>"
    ]
  },
  {
    "objectID": "timedomain_fullspace.html#inverse-transform-of-the-magnetic-field-with-step-function-excitation",
    "href": "timedomain_fullspace.html#inverse-transform-of-the-magnetic-field-with-step-function-excitation",
    "title": "8  Fields in the time domain",
    "section": "8.4 Inverse transform of the magnetic field with step function excitation",
    "text": "8.4 Inverse transform of the magnetic field with step function excitation\nThe starting point is again the equation for the magnetic field in the frequency domain.\n\\[\n    \\mathbf H(\\mathbf r) = \\frac{1}{4 \\pi r^3} \\left[\n    \\frac{\\mathbf m \\cdot \\mathbf r}{r^2} (3 + 3 i k r - k^2 r^2) \\mathbf r - (1 + i k r - k^2 r^2) \\mathbf m\n    \\right] e^{-i k r}.\n\\]\nWith the expressions for the inverse Laplace transform introduced above, we obtain the magnetic field in the time domain:\n\\[\n\\begin{align}\n\\begin{split}\n\\mathbf h(\\mathbf r, t) = & \\frac{1}{4 \\pi r^3}\n\\left[\n    \\frac{\\mathbf m \\cdot \\mathbf r}{r^2}\n    \\left(3 \\, \\mathrm{erfc}(\\Theta r) + \\left(\\frac{6}{\\sqrt{\\pi}}\\Theta r + \\frac{4}{\\sqrt{\\pi}}\\Theta^3 r^3\\right)e^{-\\Theta^2 r^2}\n    \\right) \\mathbf r \\right. - \\\\\n     &  \\left. \\left(\n    \\mathrm{erfc}(\\Theta r) + \\left(\\frac{2}{\\sqrt{\\pi}}\\Theta r + \\frac{4}{\\sqrt{\\pi}}\\Theta^3 r^3\\right)e^{-\\Theta^2 r^2}\n    \\right) \\mathbf m\n    \\right]\n    \\end{split}\n\\end{align}\n\\]\n\n\nShow the code\nfrom scipy.special import erf, erfc\ndef Ht(r, m, t, sigma):\n    mu = np.pi * 4e-7\n    R = np.linalg.norm(r)\n    theta = np.sqrt(mu * sigma / 4 / t)\n    tr = theta * R\n    t2r2 = tr**2\n    t3r3 = tr**3\n    sqpi = np.sqrt(np.pi)\n    alpha = 1.0 / (4.0 * np.pi * R**3)\n    H = alpha * (\n        np.dot(m, r) / R**2  * r\n            *\n            (3 * erfc(tr) +\n                (6 * tr / sqpi + 4 * t3r3 / sqpi) * np.exp(-t2r2)) \n                -\n            (erfc(tr) +\n                (4 * t3r3 / sqpi + 2 * tr / sqpi) * np.exp(-t2r2)) \n        * m\n        )\n\n\n    return H\n\n\n\n\nShow the code\nHt(np.array([0, 100, 0]), np.array([0, 0, 1]), 1e-0, 0.01)\n\n\narray([ 0.00000000e+00,  0.00000000e+00, -7.95774926e-08])\n\n\nHowever, the time derivative of the magnetic field is important, which is why we differentiate w.r.t. time. Using the chain rule, we obtain\n\\[\n    \\partial_t \\mathbf h(\\mathbf r, t) = \\frac{\\Theta^3}{\\sqrt{\\pi}^3 t} \\left[\n    \\Theta^2 r^2\n    \\frac{\\mathbf m \\cdot \\mathbf r}{r^2}\n    \\mathbf r -\n    (\\Theta^2 r ^2 - 1)\n    \\mathbf m\n    \\right] e^{-\\Theta^2 r^2}.\n\\]",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Fields in the time domain</span>"
    ]
  },
  {
    "objectID": "timedomain_fullspace.html#numerical-example",
    "href": "timedomain_fullspace.html#numerical-example",
    "title": "8  Fields in the time domain",
    "section": "8.5 Numerical example",
    "text": "8.5 Numerical example\n\n\nShow the code\ndef dHdt(r, m, t, sigma):\n    mu = 4e-7 * np.pi\n    R = np.linalg.norm(r)\n    \n    theta = np.sqrt(mu * sigma / 4.0 / t)\n    tr = theta * R\n    t2r2 = tr**2\n    sqpi = np.sqrt(np.pi)\n    \n    return theta**3 / sqpi**3 / t * np.exp(-t2r2) * (\n            t2r2 * np.dot(m, r) * r / R**2 +\n            (1 - t2r2) * m\n        )\n\n\nWe now simulate the step function and impulse response of the electrically conductive full space.\nWe choose \\(\\mathbf r = [100, 0, 0]^\\top\\) as the observation point. The conductivity is 0.01 S/m. The dipole moment is \\(\\mathbf m = [0 ,0 , 1]^\\top\\).\nWe simulate the fields for logarithmically equidistant times in the interval \\(10^{-7} \\le t \\le 1\\) s.\nThe simulated quantities are \\(e_y(t)\\), \\(h_z(t)\\) and \\(\\partial_t h_z(t)\\).\n\n\nShow the code\nm = np.array([0, 0, 1])\nr = np.array([100.0, 0, 0])\nsigma = 0.01\n\nnt = 71\ntt = np.logspace(-7, 0, nt, endpoint=True)\ney = np.array([Et(r, m, v, sigma)[1] for v in tt])\nhz = np.array([Ht(r, m, v, sigma)[2] for v in tt])\ndhzdt = np.array([dHdt(r, m, v, sigma)[2] for v in tt])\n\n\nThe electric field exhibits an asymptotic behaviour of \\(e \\sim t^{-5/2}\\) as \\(t \\to \\infty\\)\n\n\nShow the code\nimport matplotlib.pyplot as plt\n\ntr = lambda t: np.sqrt(np.pi * 4e-7 * sigma / 4 / t) * np.linalg.norm(r)\n\nTR = np.array([tr(t) for t in tt])\n\niind = np.argwhere(TR &gt; 1)\n\nfig, ax = plt.subplots()\nax.loglog(tt, np.abs(ey), linestyle='--')\nax.loglog(tt, [2 * np.abs(ey[-1]) * t**(-2.5) for t in tt], label=r'$\\sim t^{-5/2}$')\ntstar = tt[iind][-1][0]\nax.axvspan(tt[0], tstar, facecolor='red', alpha=0.1)\nax.axvspan(tstar, tt[-1], facecolor='green', alpha=0.1)\nax.set_xlabel(\"t in s\")\nax.set_ylim((1e-18, 1e-5))\nax.legend()\nax.set_title(r'$e_y(t)$')\nax.grid(True)\n\n\n\n\n\n\n\n\nFigure 8.1: Electric field component \\(e_y\\) due to a step-on vertical magnetic dipole in fullspace. The red and green shading indicates the regime where \\(\\Theta r &gt; 1\\) and \\(\\Theta r &lt; 1\\), resp.\n\n\n\n\n\nThe magnetic field approaches a stationary value as \\(t \\to \\infty\\).\nObviously, \\[\nh(r, t) = -\\frac{1}{4 \\pi r^3} \\text{ for } t \\to \\infty.\n\\]\nThe numerical evaluations are identical up to rounding errors.\n\n\nShow the code\nprint('h_z(r,t) = ' + str(-1.0 / (4 * np.pi * np.linalg.norm(r)**3)))\nprint('hz[-1]   = ' + str(hz[-1]))\n\n\nh_z(r,t) = -7.957747154594767e-08\nhz[-1]   = -7.957749262700399e-08\n\n\n\n\nShow the code\nfig, ax = plt.subplots()\nax.loglog(tt, np.abs(hz), linestyle='--')\n\nax.axvspan(tt[0], tstar, facecolor='red', alpha=0.1)\nax.axvspan(tstar, tt[-1], facecolor='green', alpha=0.1)\nax.set_xlabel(\"t in s\")\nax.set_ylim((1e-14, 1e-6))\n# ax.legend()\nax.set_title(r'$h_z(t)$')\nax.grid(True)\n\n\n\n\n\n\n\n\nFigure 8.2: Magnetic field component \\(h_z\\) due to a current step-on vertical magnetic dipole in fullspace. The red and green shading indicates the regime where \\(\\Theta r &gt; 1\\) and \\(\\Theta r &lt; 1\\), resp.\n\n\n\n\n\n\n\nShow the code\nfneg = np.argwhere(dhzdt &lt; 0.0)\nfpos = np.argwhere(dhzdt &gt; 0.0)\nfig, ax = plt.subplots()\nax.loglog(tt[fneg], np.abs(dhzdt[fneg]), color='C0', linestyle='--')\nax.loglog(tt[fpos], np.abs(dhzdt[fpos]), color='C0', linestyle='-')\nax.loglog(tt, [2 * np.abs(dhzdt[-1]) * t**(-2.5) for t in tt], color='C1', label=r'$\\sim t^{-5/2}$')\n\nax.axvspan(tt[0], tstar, facecolor='red', alpha=0.1)\nax.axvspan(tstar, tt[-1], facecolor='green', alpha=0.1)\nax.set_xlabel(\"t in s\")\nax.set_ylim((1e-14, 1e-2))\nax.legend()\nax.set_title(r'$\\partial_t h_z(t)$')\nax.grid(True)\n\n\n\n\n\n\n\n\nFigure 8.3: Time derivative of the magnetic field component \\(h_z\\) due to a current step-on vertical magnetic dipole in fullspace. The red and green shading indicates the regime where \\(\\Theta r &gt; 1\\) and \\(\\Theta r &lt; 1\\), resp.",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Fields in the time domain</span>"
    ]
  },
  {
    "objectID": "timedomain_fullspace.html#late-time-asymptotic-behaviour-and-apparent-resistivity",
    "href": "timedomain_fullspace.html#late-time-asymptotic-behaviour-and-apparent-resistivity",
    "title": "8  Fields in the time domain",
    "section": "8.6 Late-time asymptotic behaviour and apparent resistivity",
    "text": "8.6 Late-time asymptotic behaviour and apparent resistivity\nThe resistivity of the full space can be reconstructed from the late-time asymptotics of \\(\\partial_t \\mathbf h(t)\\).\nFor \\(t \\to \\infty\\) the late-time asymptotics is\n\\[\n\\partial_t \\mathbf h^L(t) = \\frac{\\Theta^3(t)}{\\sqrt{\\pi}^3 t} = \\frac{1}{8} \\left(\\frac{\\mu\\sigma}{\\pi}\\right)^{3/2} t^{-5/2} \\mathbf m.\n\\]\nWe do not recognize any dependence on the distance \\(r\\).\nFrom the asymptotic behaviour of the late-time, we can reconstruct the conductivity of the full space directly from the measured variable.\nFor example, the following applies for \\(\\mathbf m = (0, 0, m)^\\top\\):\n\\[\n\\sigma = \\frac{4 \\pi}{\\mu} \\left( \\frac{1}{m} \\partial_t h_z(t) \\right)^{2/3} t^{5/3}\n\\]\n\n\nShow the code\nmu0 = np.pi * 4e-7\nsig_a = np.array([4 * np.pi / mu0 * np.abs(u)**(2/3) * v**(5/3) for u, v in zip(dhzdt, tt)])\nfig, ax = plt.subplots()\n\nax.loglog(tt, sig_a)\nax.axvspan(tt[0], tstar, facecolor='red', alpha=0.1)\nax.axvspan(tstar, tt[-1], facecolor='green', alpha=0.1)\nax.hlines(sigma, tt[0], tt[-1], linestyle='--', color='C1', label='True conductivity')\nax.legend()\nax.set_ylim((1e-5, 1e-1))\nax.set_xlabel('t in s')\nax.set_ylabel(r'$\\sigma~in~S/m$')\nax.grid(True)\n\n\n\n\n\n\n\n\nFigure 8.4: Apparent conductivity evaluated from the late-time asymptotics. The red and green shading indicates the regime where \\(\\Theta r &gt; 1\\) and \\(\\Theta r &lt; 1\\), resp.",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Fields in the time domain</span>"
    ]
  },
  {
    "objectID": "halfspace.html",
    "href": "halfspace.html",
    "title": "9  Dipole sources above a halfspace",
    "section": "",
    "text": "9.1 Uniform halfspace",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dipole sources above a halfspace</span>"
    ]
  },
  {
    "objectID": "halfspace.html#layered-halfspace",
    "href": "halfspace.html#layered-halfspace",
    "title": "9  Dipole sources above a halfspace",
    "section": "9.2 Layered halfspace",
    "text": "9.2 Layered halfspace",
    "crumbs": [
      "Dipole induction",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Dipole sources above a halfspace</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "10  Summary",
    "section": "",
    "text": "WIP",
    "crumbs": [
      "Summary",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Abramowitz, M. & Stegun, I.A., 1972. Handbook of mathematical\nfunctions with formulas, graphs, and mathematical tables, Tenth.,\nDover Publications.\n\n\nWard, S.H. & Hohmann, G.W., 1988. Electromagnetic theory for\ngeophysical applications. Electromagnetic methods in applied\ngeophysics, Vol. 1, pp. 131–311.",
    "crumbs": [
      "References"
    ]
  }
]